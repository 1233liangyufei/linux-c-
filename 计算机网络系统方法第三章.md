# 第3章：网络互联

> 自然似乎......通过漫长的迂回路线到达她的许多目的。 *-Rudolph Lotze*

## 问题：并非所有网络都是直接连接的

正如我们所看到的，有许多技术可用于构建最后一英里链接或将少量节点连接在一起，但我们如何构建全球规模的网络？单个以太网可以互连不超过1024台主机; 点对点链接仅连接两个。无线网络受其无线电范围的限制。要构建全球网络，我们需要一种方法来互连这些不同类型的链路和多接入网络。将不同类型的网络互连以构建大型全球网络的概念是因特网的核心思想，并且通常被称为 *网络互联*。

我们可以将网络互联问题分成几个子问题。首先，我们需要一种互连链接的方法。互连相同类型链路的设备通常称为*交换机*，有时也称为*第2层*（L2）交换机。这些设备是本章的第一个主题。目前使用的一类特别重要的L2交换机是用于互连以太网网段的交换机。这些开关有时也称为*桥*。

交换机的核心工作是接收到达输入的数据包， 并将它们*转发*（或*切换*）到正确的输出，以便它们到达适当的目的地。交换机可以通过多种方式确定数据包的“正确”输出，这可以大致分为无连接和面向连接的方法。这两种方法多年来都发现了重要的应用领域。

鉴于网络类型的多样性，我们还需要一种互连不同网络和链接的方法（即处理 *异构性*）。执行此任务的设备（称为 *网关*）现在主要称为*路由器*，或者 称为*第3层*（L3）交换机。为解决不同网络类型（互联网协议（IP））的互连而发明的协议是我们第二部分的主题。

一旦我们将大量链路和网络与交换机和路由器互连，就可能有许多不同的可能方式从一个点到另一个点。通过网络寻找合适的路径或*路由*是网络的基本问题之一。这样的路径应该是有效的（例如，不长于必要的），无环路，并且能够响应网络不是静态的事实 - 节点可能失败或重新启动，链路可能中断，并且可以添加新节点或链路。我们的第三部分介绍了为解决这些问题而开发的一些算法和协议。

一旦我们了解了切换和路由的问题，我们就需要一些设备来执行这些功能。本章最后讨论了交换机和路由器的实现方式。虽然许多分组交换机和路由器与通用计算机非常相似，但是在许多情况下使用更专业的设计。在高端尤其如此，似乎永远需要更多的交换容量来处理互联网核心中不断增加的流量负载。

# [3.1交换和桥接](https://book.systemsapproach.org/)

简而言之，交换机是一种允许我们互连链路以形成更大网络的机制。交换机是一种多输入多输出设备，可将数据包从输入传输到一个或多个输出。因此，交换机将星型拓扑（参见[图1](https://book.systemsapproach.org/internetworking/switching.html#star)）添加到可能的网络结构集中。星型拓扑具有几个吸引人的特性：

- 即使交换机具有固定数量的输入和输出，这限制了可以连接到单个交换机的主机数量，也可以通过互连多个交换机来构建大型网络。
- 我们可以使用点对点链接将交换机相互连接到主机，这通常意味着我们可以构建具有大地理范围的网络。
- 通过将新主机连接到交换机将新主机添加到网络不一定会降低已连接的其他主机的网络性能。

![img](https://book.systemsapproach.org/internetworking/figures/f03-01-9780123850591.png)交换机提供星型拓扑。

对于上一章中讨论的共享媒体网络，不能提出最后一项权利要求。例如，同一10-Mbps以太网段上的两台主机不可能以10 Mbps的速度连续发送，因为它们共享相同的传输介质。交换网络上的每个主机都有自己的交换机链路，因此，如果交换机设计有足够的总容量，许多主机可能完全可以以完整链路速度（带宽）进行传输。提供高聚合吞吐量是交换机的设计目标之一; 我们稍后再回到这个主题。通常，交换网络被认为比共享媒体网络更具*可扩展性*（即，更能够增长到大量节点），因为这种能力可以全速支持许多主机。

交换机连接到一组链路，并且对于这些链路中的每一个，运行适当的数据链路协议以与链路另一端的节点通信。交换机的主要工作是在其中一个链路上接收传入的数据包，并在其他链路上传输它们。此功能有时被称为*切换*或 *转发，*并且就开放系统互连（OSI）架构而言，它是网络层的主要功能，也称为*第2层*。

那么，问题是交换机如何决定将每个数据包放在哪个输出链路上？一般的答案是，它会查看数据包的标头，以查找用于做出决策的标识符。它如何使用此标识符的详细信息各不相同，但有两种常见方法。第一种是*数据报*或无*连接*方法。第二种是*虚拟电路*或*面向连接的*方法。第三种方法，即*源路由*，不如其他两种方法常见，但它确实有一些有用的应用。

所有网络都有一个共同点，就是我们需要有一种方法来识别终端节点。这种标识符通常称为 *地址*。我们已经看到了地址的例子，例如用于以太网的48位地址。以太网地址的唯一要求是网络上没有两个节点具有相同的地址。这是通过确保为所有以太网卡分配*全局唯一*标识符来实现的。对于以下讨论，我们假设每个主机具有全局唯一的地址。稍后，我们会考虑地址可能具有的其他有用属性，但全局唯一性足以让我们开始。

我们需要做的另一个假设是，有一些方法可以识别每个交换机的输入和输出端口。至少有两种明智的方法来识别端口：一种是为每个端口编号，另一种是通过它所引导的节点（交换机或主机）的名称来识别端口。目前，我们使用端口编号。

## 数据报

数据报背后的想法非常简单：您只需在每个数据包中包含足够的信息，以使任何交换机能够决定如何将其发送到目的地。也就是说，每个数据包都包含完整的目标地址。考虑[图2](https://book.systemsapproach.org/internetworking/switching.html#dgram)中[所示](https://book.systemsapproach.org/internetworking/switching.html#dgram)的示例网络 ，其中主机具有地址A，B，C等。为了决定如何转发数据包，交换机会查询*转发表*（有时称为*路由表*），其示例如[表1](https://book.systemsapproach.org/internetworking/switching.html#fwdtab)所示。。该特定表显示了交换机2在示例网络中转发数据报所需的转发信息。当你有一个像这里描述的简单网络的完整地图时，很容易弄清楚这样的表格; 我们可以想象网络运营商静态配置表。在具有动态变化的拓扑和目的地之间的多条路径的大型复杂网络中创建转发表要困难得多。这个更难的问题被称为*路由，*并且是后面部分的主题。我们可以将路由视为在后台进行的过程，这样，当数据包出现时，我们将在转发表中拥有正确的信息，以便能够转发或切换数据包。

![img](https://book.systemsapproach.org/internetworking/figures/f03-02-9780123850591.png)数据报转发：示例网络。



交换机2的转发表。

| 目的地 | 港口 |
| :----: | :--: |
|  一个  |  3   |
|   乙   |  0   |
|   C    |  3   |
|   d    |  3   |
|   Ë    |  2   |
|   F    |  1   |
|   G    |  0   |
|   H    |  0   |

数据报网络具有以下特征：

- 主机可以随时随地发送数据包，因为任何在交换机处出现的数据包都可以立即转发（假设转发表正确填充）。出于这个原因，数据报网络通常被称为无*连接* ; 这与下面描述*的面向连接的*网络形成对比 ，其中在发送第一个数据包之前需要建立一些 *连接状态*。
- 当主机发送数据包时，它无法知道网络是否能够提供数据包，或者目标主机是否已启动并正在运行。
- 每个数据包都可以独立于先前可能已发送到同一目的地的数据包进行转发。因此，从主机A到主机B的两个连续分组可以遵循完全不同的路径（可能是由于网络中某个交换机处的转发表的变化）。
- 如果可以找到故障周围的备用路由并相应地更新转发表，则交换机或链路故障可能不会对通信产生任何严重影响。

最后一个事实对数据报网络的历史尤为重要。互联网的一个重要设计目标是对故障的稳健性，历史证明它在实现这一目标方面非常有效。

## 虚电路交换

用于分组交换的第二种技术与数据报模型显着不同，它使用*虚拟电路*（VC）的概念。此方法（也称为*面向连接的模型*）需要在发送任何数据之前设置从源主机到目标主机的虚拟连接。要了解其工作原理，请考虑[图3](https://book.systemsapproach.org/internetworking/switching.html#vcircuit)，其中主机A再次想要将数据包发送到主机B.我们可以将其视为一个两阶段过程。第一阶段是“连接设置”。第二是数据传输。我们依次考虑每一个。

![img](https://book.systemsapproach.org/internetworking/figures/f03-03-9780123850591.png)虚电路网络的一个例子。

在连接建立阶段，必须在源主机和目标主机之间的每个交换机中建立“连接状态”。单个连接的连接状态由连接所通过的每个交换机中的“VC表”中的条目组成。单个交换机上VC表中的一个条目包含：

- 甲*虚电路标识符*（VCI），其唯一地标识在该开关的连接，并其将属于该连接的分组的报头内进行
- 传入接口，此VC的数据包到达交换机
- 一个出接口，该VC的数据包离开交换机
- 可能用于传出数据包的可能不同的VCI

一个这样的条目的语义如下：如果一个数据包到达指定的传入接口，并且该数据包在其报头中包含指定的VCI值，那么该数据包应该从指定的传出接口发送出来，并且指定的传出VCI值已被首先放在它的标题中。

需要注意的是，因为它们是在开关接收到的分组的VCI的组合*和*它们在其上接收的接口唯一地标识该虚拟连接。当然可以在交换机中一次建立许多虚拟连接。此外，我们观察到传入和传出的VCI值通常不相同。因此，VCI不是连接的全局重要标识符; 相反，它仅在给定链接上具有重要性（即，它具有 *链接本地范围*）。

无论何时创建新连接，我们都需要在连接将遍历的每个链路上为该连接分配新的VCI。我们还需要确保某个现有连接上当前未在该链路上使用给定链路上所选的VCI。

建立连接状态有两种广泛的方法。一种是让网络管理员配置状态，在这种情况下虚拟电路是“永久的”。当然，它也可以由管理员删除，因此永久虚拟电路（PVC）最好被认为是一个长期或管理配置的VC。或者，主机可以将消息发送到网络以使状态建立。这被称为*信令*，并且所产生的虚拟电路被称为被*切换*。切换虚拟电路（SVC）的显着特征是主机可以在没有网络管理员参与的情况下动态地建立和删除这样的VC。请注意，SVC应更准确地称为*信号* VC，因为使用信令（而不是切换）来区分SVC和PVC。

假设网络管理员想要手动创建从主机A到主机B的新虚拟连接。首先，管理员需要识别从A到B的网络路径。在[图3](https://book.systemsapproach.org/internetworking/switching.html#vcircuit)的示例网络中，只有一个这样的道路，但总的来说，情况可能并非如此。然后，管理员选择当前在连接的每个链接上未使用的VCI值。出于我们的示例的目的，让我们假设从主机A到交换机1的链路选择VCI值5，并且从交换机1到交换机2的链路选择11.在这种情况下，交换机1需要具有VC表中的一个条目，如[表2](https://book.systemsapproach.org/internetworking/switching.html#vctab)所示。



交换机1的虚拟电路表条目示例。

| 传入接口 | 传入的VCI | 传出接口 | 外出VCI |
| :------: | :-------: | :------: | :-----: |
|    2     |    五     |    1     |   11    |

类似地，假设选择VCI为7以识别从交换机2到交换机3的链路上的该连接，并且选择VCI为4用于从交换机3到主机B的链路。在这种情况下，交换机2和3需要配置VC表项，如[表3](https://book.systemsapproach.org/internetworking/switching.html#vctab1)所示 。注意，一个开关处的“输出”VCI值是下一个开关处的“输入”VCI值。



交换机2和3的虚拟电路表条目。

Switch 2的VC表项：

| 传入接口 | 传入的VCI | 传出接口 | 外出VCI |
| :------: | :-------: | :------: | :-----: |
|    3     |    11     |    2     |    7    |

Switch 3上的VC表项：

| 传入接口 | 传入的VCI | 传出接口 | 外出VCI |
| :------: | :-------: | :------: | :-----: |
|    0     |     7     |    1     |    4    |

![img](https://book.systemsapproach.org/internetworking/figures/f03-04-9780123850591.png)数据包被发送到虚拟电路网络。

一旦设置了VC表，数据传输阶段就可以继续，[如图4所示](https://book.systemsapproach.org/internetworking/switching.html#vcdat)。对于要发送给主机B的任何数据包，A将VCI值5放在数据包的标头中并将其发送到交换机1.交换机1在接口2上接收任何此类数据包，并使用接口的组合和包头中的VCI找到合适的VC表项。如[表2](https://book.systemsapproach.org/internetworking/switching.html#vctab)所示， 这种情况下的表条目告诉交换机1将数据包转发出接口1，并在发送数据包时将VCI值11放入标题中。因此，数据包将到达带有VCI 11的接口3上的交换机2.交换机2在其VC表中查找接口3和VCI 11（如[表3](https://book.systemsapproach.org/internetworking/switching.html#vctab1)所示）在适当更新数据包报头中的VCI值后，将数据包发送到交换机3，[如图5](https://book.systemsapproach.org/internetworking/switching.html#vcdat2)所示。此过程继续，直到它到达主机B，数据包中的VCI值为4。要托管B，这会将数据包标识为来自主机A.

在合理大小的实际网络中，使用上述过程很快就会在大量交换机中正确配置VC表的负担。因此，即使在设置“永久”VC时，也几乎总是使用网络管理工具或某种信令（或两者）。在PVC的情况下，信令由网络管理员发起，而SVC通常由其中一个主机使用信令建立。我们现在考虑如何通过来自主机的信令建立刚刚描述的相同VC。

![img](https://book.systemsapproach.org/internetworking/figures/f03-05-9780123850591.png)数据包通过虚拟电路网络。

为了启动信令过程，主机A向网络发送设置消息 - 即切换1.设置消息包含主机B的完整目标地址等。设置消息需要一直到达B在沿途的每个开关中创建必要的连接状态。我们可以看到将设置消息发送到B就像将数据报发送到B一样，因为交换机必须知道将设置消息发送到哪个输出，以便它最终到达B.现在，让我们假设交换机对网络拓扑有足够的了解，以弄清楚如何做到这一点，以便设置消息在最终到达主机B之前流向交换机2和3。

当交换机1接收到连接请求时，除了将其发送到交换机2之外，它还在其虚拟电路表中为该新连接创建新条目。此条目与先前[表2中](https://book.systemsapproach.org/internetworking/switching.html#vctab)显示的完全相同。主要区别在于，现在在接口上分配未使用的VCI值的任务是由该端口的交换机执行的。在此示例中，交换机选择值5.虚拟电路表现在具有以下信息：“当数据包到达具有标识符5的端口2时，在端口1上发送它们。” 另一个问题是，不知何故，主机A需要知道它应该将VCI值5放在它想要发送给B的数据包中; 我们将在下面看到这种情况。

当交换机2接收到建立消息时，它执行类似的过程; 在此示例中，它选择值11作为传入的VCI值。类似地，交换机3选择7作为其输入VCI的值。每个交换机都可以选择它喜欢的任何号码，只要该号码当前不用于该交换机该端口上的某些其他连接。如上所述，VCI具有链路本地范围; 也就是说，它们没有全球意义。

最后，设置消息作为主机B到达。假设B健康且愿意接受来自主机A的连接，它也分配一个传入的VCI值，在这种情况下为4.B可以使用该VCI值来识别所有数据包来自主持人A.

现在，为了完成连接，每个人都需要被告知他们的下游邻居正在使用什么作为此连接的VCI。主机B向交换机3发送连接建立确认，并在该消息中包括它选择的VCI（4）。现在，交换机3可以完成此连接的虚拟电路表条目，因为它知道输出值必须为4.交换机3将确认发送到交换机2，指定VCI为7.交换机2将消息发送到交换机1，指定VCI为11.最后，交换机1将确认传递给主机A，告诉它使用5的VCI进行此连接。

此时，每个人都知道允许流量从主机A流向主机B所需的全部内容。每个交换机都有一个完整的虚拟电路表条目用于连接。此外，主机A确认所有内容都存在于主机B的所有位置。此时，连接表条目在所有三个交换机中都已就位，就像上面的管理配置示例一样，但整个过程自动发生响应从A发送的信令消息。数据传输阶段现在可以开始并且与PVC情况中使用的相同。

当主机A不再想要向主机B发送数据时，它通过向交换机1发送拆除消息来断开连接。交换机从其表中删除相关条目并将消息转发到路径中的其他交换机，同样删除相应的表条目。此时，如果主机A要将VCI为5的数据包发送到交换机1，它将被丢弃，就好像连接从未存在过一样。

虚拟电路交换有几点需要注意：

- 由于主机A必须等待连接请求到达网络的远端并且在它可以发送其第一数据分组之前返回，因此在发送数据之前存在至少一个延迟的往返时间（RTT）。
- 虽然连接请求包含主机B的完整地址（可能非常大，是网络上的全局标识符），但每个数据包仅包含一个小标识符，该标识符仅在一个链路上是唯一的。因此，由报头引起的每分组开销相对于数据报模型减少。更重要的是，查找速度很快，因为虚拟电路号可以被视为表的索引，而不是必须被查找的键。
- 如果连接中的交换机或链路出现故障，则连接断开，需要建立新连接。此外，旧的需要拆除以释放交换机中的表存储空间。
- 关于交换机如何决定转发连接请求的链接的问题已被掩盖。实质上，这与构建数据报转发转发表的问题相同，这需要某种*路由算法*。路由在稍后的部分中描述，并且其中描述的算法通常适用于路由设置请求以及数据报。

虚拟电路的一个不错的方面是，当主机获得发送数据时，它对网络有很多了解 - 例如，确实存在到接收器的路由，接收器是愿意并且能够接收数据。还可以在建立虚拟电路时将资源分配给虚拟电路。例如，X.25（早期和现在基本上已过时的基于虚拟电路的网络技术）采用以下三部分策略：

1. 当电路初始化时，缓冲器被分配给每个虚拟电路。
2. 滑动窗口协议在沿着虚拟电路的每对节点之间运行，并且该协议通过流控制来增强，以防止发送节点过度运行在接收节点处分配的缓冲区。
3. 如果在处理连接请求消息时该节点上没有足够的缓冲区，则给定节点拒绝该电路。

在做这三件事时，确保每个节点具有对到达该电路的数据包进行排队所需的缓冲区。这种基本策略通常称为*逐跳流控制。*

相比之下，数据报网络没有连接建立阶段，每个交换机独立处理每个数据包，这使得数据报网络如何以有意义的方式分配资源变得不那么明显。相反，每个到达的数据包与所有其他数据包竞争缓冲空间。如果没有空闲缓冲区，则必须丢弃传入的数据包。但是，我们观察到，即使在基于数据报的网络中，源主机也经常将一系列数据包发送到同一目标主机。每个交换机可以根据源/目的地对区分它当前已排队的数据包集合，从而使交换机能够确保属于每个源/目的地对的数据包正在接收相应的数据包。切换缓冲区。

在虚拟电路模型中，我们可以想象为每个电路提供不同*的服务质量*（QoS）。在此设置中，术语 *服务质量*通常用于表示网络为用户提供某种与性能相关的保证，这反过来意味着交换机会留出满足此保证所需的资源。例如，沿着给定虚拟电路的交换机可以将每个输出链路带宽的百分比分配给该电路。作为另一个例子，一系列交换机可以确保属于特定电路的分组不被延迟（排队）超过一定量的时间。

多年来已经有许多成功的虚电路技术实例，特别是X.25，帧中继和异步传输模式（ATM）。然而，随着互联网无连接模式的成功，它们今天都没有受到欢迎。多年来虚拟电路最常见的应用之一是构建*虚拟专用网络*（VPN），这是后面部分讨论的主题。现在，即使该应用程序也主要使用基于Internet的技术来支持。

### 异步传输模式（ATM）

异步传输模式（ATM）可能是最着名的基于虚拟电路的网络技术，尽管它在部署方面已经远远超过其峰值。ATM成为20世纪80年代和90年代初期的一项重要技术，其原因有多种，其中最重要的是它被电话行业所接受，当时电信行业在计算机网络中的活跃程度较低（除供应商外）其他人建立网络的链接）。ATM也恰好在正确的时间出现在适当的地方，作为一种高速交换技术出现在现场，就像以太网和令牌环等共享媒体开始对许多计算机网络用户来说看起来有点太慢了。在某些方面，ATM是一种采用以太网交换技术的竞争技术，许多人认为它也是IP的竞争对手。

![img](https://book.systemsapproach.org/internetworking/figures/f03-06-9780123850591.png)UNI的ATM信元格式。

ATM采用的方法有一些有趣的属性，值得进一步研究。ATM数据包格式的图片 - 通常称为ATM信*元* - 在 [图6中](https://book.systemsapproach.org/internetworking/switching.html#atmcell)将说明要点。我们将跳过通用流控制（GFC）位，这些位从未被广泛使用，并且从标记为VPI（虚拟路径标识符-8位）和VCI（虚拟电路标识符-16位）的24位开始。如果将这些位一起视为单个24位字段，则它们对应于上面介绍的虚拟电路标识符。将该字段分成两部分的原因是允许一定程度的层次结构：在某些情况下，所有具有相同VPI的电路都可以被视为一个组（虚拟路径），并且可以全部切换到一起看VPI，简化了可忽略所有VCI位并大大减小VC表大小的交换机的工作。

跳到最后一个头字节，我们发现了一个8位循环冗余校验（CRC），称为*头错误检查*（`HEC`）。它使用CRC-8，仅在单元头上提供错误检测和单比特纠错功能。保护单元头是特别重要的，因为错误`VCI`将导致单元被错误传送。

关于ATM信元的最重要的事情，以及它被称为信元而不是数据包的原因，可能是它只有一个大小：53字节。这是什么原因？一个重要原因是促进硬件开关的实施。当ATM在80年代中期和后期创建时，10-Mbps以太网在速度方面是最先进的技术。为了更快，大多数人都考虑硬件。此外，在电话世界中，当人们想到交换机时，人们会认为很大 - 电话交换机通常会为成千上万的客户提供服务。如果您想构建快速，高度可扩展的交换机，定长数据包将变得非常有用。这有两个主要原因：

1. 构建硬件来完成简单的工作更容易，当你已经知道每个工作的时间长时，处理数据包的工作就更简单了。
2. 如果所有数据包的长度都相同，那么你可以让许多交换元素并行执行相同的操作，每个交换元素都花费相同的时间来完成它的工作。

第二个原因是并行性的实现，极大地提高了交换机设计的可扩展性。如果说快速并行硬件开关只能使用固定长度的单元构建，那将夸大这种情况。然而，毫无疑问，单元可以简化构建此类硬件的任务，并且在定义ATM标准时，有很多关于如何在硬件中构建单元交换机的知识。事实证明，今天在许多交换机和路由器中仍然应用了同样的原则，即使它们处理可变长度的数据包 - 它们将这些数据包切换到某种单元格，以便将它们从输入端口转发到输出端口，但是都在交换机内部。

还有另一个有利于小型ATM信元的好理由，与端到端延迟有关。ATM旨在承载语音电话（当时的主要用例）和数据。因为语音是低带宽但具有严格的延迟要求，所以你想要的最后一件事是在交换机上排队大数据包后排队的小型语音数据包。如果强制所有数据包都很小（即，小区大小），那么通过将一组信元重新组合成数据包仍然可以支持大数据包，并且您可以获得能够交错语音信元的转发和从源到目的地的每个交换机上的数据单元。使用小型小区来改善端到端延迟的这种想法在蜂窝接入网络中仍然存在。

决定使用小的，固定长度的数据包，接下来的问题是修复它们的正确长度是多少？如果使它们太短，那么相对于适合一个单元的数据量需要携带的头信息量会变大，因此实际用于承载数据的链路带宽百分比会下降。更严重的是，如果您构建一个以每秒最大单元数处理单元的设备，那么随着单元变短，总数据速率会与单元大小成正比地下降。这种设备的一个例子可能是网络适配器，它在将信元传递给主机之前将信元重新组装成更大的单元。这种设备的性能直接取决于单元尺寸。另一方面，如果你让细胞太大，然后存在由于需要填充传输数据以填充完整单元而导致带宽浪费的问题。如果单元有效负载大小为48个字节，并且您希望发送1个字节，则需要发送47个字节的填充。如果这种情况发生很多，那么链接的利用率将非常低。相对较高的报头与有效载荷比率加上发送部分填充小区的频率的组合实际上导致ATM网络中一些显着的低效率，一些批评者称之为*细胞税*。

事实证明，作为折衷方案，为ATM信元有效载荷挑选了48个字节。对于较大和较小的单元都有很好的论据，而且48几乎没有人满意 - 对于计算机来说，2的强度当然会更好。

## 源路由

第三种既不使用虚拟电路也不使用传统数据报的切换方法称为*源路由*。该名称源于以下事实：源主机提供了通过网络切换数据包所需的所有网络拓扑信息。

有多种方法可以实现源路由。一种方法是为每个交换机的每个输出分配一个数字，并将该数字放在数据包的标题中。切换功能非常简单：对于到达输入的每个数据包，交换机将读取报头中的端口号并在该输出上传输数据包。但是，由于在发送和接收主机之间的路径中通常会有多个交换机，因此数据包的报头需要包含足够的信息以允许路径中的每个交换机确定数据包需要放置的输出上。一种方法是在标题中放置一个有序的交换机端口列表并旋转列表，以便路径中的下一个开关始终位于列表的前面。[图7](https://book.systemsapproach.org/internetworking/switching.html#source-route) 说明了这个想法。

![img](https://book.systemsapproach.org/internetworking/figures/f03-07-9780123850591.png)交换网络中的源路由（交换机读取最右边的数字）。

在这个例子中，数据包需要遍历三个交换机以从主机A到主机B.在交换机1，它需要在端口1上退出，在下一个交换机需要从端口0退出，在第三个交换机它需要在端口3处退出。因此，当数据包离开主机A时的原始头包含端口列表（3,0,1），其中我们假设每个交换机读取列表中最右边的元素。为了确保下一个开关获得适当的信息，每个开关在读取其自己的条目后旋转列表。因此，当交换机1路由到交换机2时的分组报头现在是（1,3,0）; 交换机2执行另一次旋转，并在报头中发送一个包含（0,1,3）的数据包。尽管未示出，但是交换机3执行另一次旋转，将报头恢复到主机A发送它时的状态。

关于这种方法有几点需要注意。首先，它假设主机A对网络的拓扑结构有足够的了解，以形成一个标头，该标头中包含路径中每个交换机的所有正确方向。这有点类似于在数据报网络中构建转发表或确定在虚拟电路网络中发送设置分组的位置的问题。然而，实际上，它是连接到源路由的网络入口处的第一个交换机（与连接到该交换机的终端主机相对）。

其次，观察我们无法预测标头需要多大，因为它必须能够为路径上的每个开关保持一个信息字。这意味着标头可能具有可变长度而没有上限，除非我们可以绝对确定地预测数据包将需要通过的最大交换机数量。

第三，这种方法有一些变化。例如，不是旋转标题，每个开关都可以在使用它时剥离第一个元素。然而，旋转比剥离有一个优势：主机B获得完整标头的副本，这可能有助于它找出如何返回主机A.另一种方法是让标头携带指向当前“下一个端口”的指针“进入，以便每个开关只更新指针而不是旋转标题; 这可能更有效地实施。我们在[图8中](https://book.systemsapproach.org/internetworking/switching.html#sroute-app)展示了这三种方法。在每种情况下，此交换机需要读取`A`的条目是，以及下一个交换机需要读取的条目`B`。

![img](https://book.systemsapproach.org/internetworking/figures/f03-08-9780123850591.png)处理源路由头的三种方法：（a）旋转; （b）剥离; （c）指针。标签从右到左阅读。

源路由可以用于数据报网络和虚拟电路网络。例如，作为数据报协议的因特网协议包括源路由选项，其允许选择的分组被源路由，而大多数被切换为传统的数据报。源路由也用于某些虚拟电路网络，作为从源到目的地的路径获取初始设置请求的手段。

源路由有时被分类为*严格*或*松散*。在严格的源路由中，必须指定路径上的每个节点，而松散的源路由仅指定要遍历的一组节点，而不确切地说明如何从一个节点到达下一个节点。松散的源路由可以被认为是一组路点而不是完全指定的路径。松散选项有助于限制源必须获取的信息量以创建源路由。在任何相当大的网络中，主机很难获得构建正确的到任何目的地的严格源路由所需的完整路径信息。但是这两种类型的源路由确实可以在某些场景中找到应用，我们将在后面的章节中看到。

## 网桥和L2交换机

在讨论了切换背后的一些基本思想之后，我们现在更加关注某些特定的交换技术。我们首先考虑一类用于在LAN（局域网）（如以太网）之间转发数据包的交换机。这种开关现在称为L2开关; 从历史上看，它们也被称为*桥梁*，它们在校园和企业网络中得到了广泛的应用。

假设您有一对要互连的以太网。您可能尝试的一种方法是在它们之间放置一个转发器。但是，如果这样做超出了以太网的物理限制，那么这将不是一个可行的解决方案。（回想一下，允许在任何一对主机之间不超过两个中继器，总长度不超过2500米。）另一种方法是在两个以太网之间放置一个带有一对以太网适配器的节点并拥有节点将帧从一个以太网转发到另一个以太网。该节点与转发器不同，转发器对比特而不是帧进行操作，并且只是盲目地将在一个接口上接收的比特复制到另一个接口。相反，该节点将在每个接口上完全实现以太网的冲突检测和媒体访问协议。因此，以太网的长度和主机数量限制都是关于管理冲突的，并不适用于以这种方式连接的组合的以太网网络。该设备以混杂模式运行，接受在任一以太网上传输的所有帧，并将它们转发到另一个。

我们刚刚描述的节点通常称为*网桥*，并且通常认为由一个或多个网桥连接的LAN集合形成*扩展LAN*。在最简单的变体中，桥接器只接受其输入上的LAN帧，并将其转发到所有其他输出上。这种简单的策略被早期桥梁使用，但有一些非常严重的限制，我们将在下面看到。多年来已经添加了许多改进，以使桥接器成为互连一组LAN的有效机制。本节的其余部分填写了更有趣的细节。

请注意，网桥符合我们对上一节中交换机的定义：多输入多输出设备，它将数据包从输入传输到一个或多个输出。请记住，这提供了一种增加网络总带宽的方法。例如，虽然单个以太网段可能仅承载100 Mbps的总流量，但以太网桥可承载多达100个ñ*n* Mbps，在哪里ñ*n*是网桥上的端口数（输入和输出）。

### 学习桥梁

我们可以对桥进行的第一个优化是观察它不需要转发它接收的所有帧。考虑[图9中](https://book.systemsapproach.org/internetworking/switching.html#elan2)的桥 。每当来自主机A的寻址到主机B的帧到达端口1时，网桥就不需要通过端口2将帧转发出来了。那么，问题是如何通过桥来了解哪个端口是各种主机居住？

![img](https://book.systemsapproach.org/internetworking/figures/f03-09-9780123850591.png)一座学习桥梁的例证。

一种选择是让人类将一张表下载到桥中，类似于[表4中](https://book.systemsapproach.org/internetworking/switching.html#learn)给出的[表](https://book.systemsapproach.org/internetworking/switching.html#learn)。然后，每当网桥在端口1上接收到寻址到主机A的帧时，它就不会在端口2上转发帧; 没有必要，因为主机A已经直接接收到连接到端口1的LAN上的帧。无论何时在端口2上接收到寻址到主机A的帧，网桥都会在端口1上转发帧。



由桥梁维护的转发表。

| 主办 | 港口 |
| :--: | :--: |
| 一个 |  1   |
|  乙  |  1   |
|  C   |  1   |
|  X   |  2   |
|  ÿ   |  2   |
|  ž   |  2   |

实际上，没有人构建用于手动配置表的桥。让人类维护这个表格太繁琐了，并且有一个简单的技巧可以让桥梁自己学习这些信息。这个想法是让每个网桥检查它收到的所有帧中的*源*地址。因此，当主机A向网桥任一侧的主机发送帧时，网桥接收该帧并记录端口1刚刚接收到来自主机A的帧的事实。这样，网桥可以构建一个表就像[表4一样](https://book.systemsapproach.org/internetworking/switching.html#learn)。

注意，使用这种表的桥实现了前面描述的转发数据报（或无连接）模型的版本。每个数据包都携带一个全局地址，并且网桥通过在表中查找该地址来决定将数据包发送到哪个输出。

当桥首次启动时，此表为空; 随着时间的推移添加条目。此外，超时与每个条目相关联，并且网桥在指定的时间段后丢弃该条目。这是为了防止主机 - 以及因此其LAN地址 - 从一个网络移动到另一个网络的情况。因此，该表不一定完整。如果网桥收到一个寻址到当前不在表中的主机的帧，它将继续前进并在所有其他端口上转发帧。换句话说，这个表只是一个过滤掉一些帧的优化; 它不是正确性所必需的。

### 履行

实现学习桥算法的代码非常简单，我们在此草拟它。结构`BridgeEntry`定义了网桥转发表中的单个条目; 这些被存储在`Map`结构（支持`mapCreate`，`mapBind`和`mapResolve`操作），以使条目被有效地位于当包在表中从源到达了。常量`MAX_TTL`指定条目在丢弃之前保留在表中的时间长度。

```c
#define BRIDGE_TAB_SIZE   1024  /* max size of bridging table */
#define MAX_TTL           120   /* time (in seconds) before an entry is flushed */

typedef struct {
    MacAddr     destination;    /* MAC address of a node */
    int         ifnumber;       /* interface to reach it */
    u_short     TTL;            /* time to live */
    Binding     binding;        /* binding in the Map */
} BridgeEntry;

int     numEntries = 0;
Map     bridgeMap = mapCreate(BRIDGE_TAB_SIZE, sizeof(BridgeEntry));
```

新数据包到达时更新转发表的例程由下式给出`updateTable`。传递的参数是数据包中包含的源媒体访问控制（MAC）地址以及接收它的接口号。此处未显示的另一个例程，定期调用，扫描转发表中的条目，并递减`TTL`每个条目的（生存时间）字段，丢弃`TTL`已达到0的任何条目。请注意，每次`TTL`都重置 该条目`MAX_TTL`数据包到达以刷新现有表条目，并且更新目标可以到达的接口以反映最近接收的数据包。

```c
void 
updateTable (MacAddr src, int inif) 
{
    BridgeEntry       *b;

    if (mapResolve(bridgeMap, &src, (void **)&b) == FALSE ) 
    {
        /* this address is not in the table, so try to add it */
        if (numEntries < BRIDGE_TAB_SIZE) 
        {
            b = NEW(BridgeEntry);
            b->binding = mapBind( bridgeMap, &src, b);
            /* use source address of packet as dest. address in table */
            b->destination = src;
            numEntries++;
        }
        else 
        {
            /* can`t fit this address in the table now, so give up */
            return;
        }
    }
    /* reset TTL and use most recent input interface */
    b->TTL = MAX_TTL;
    b->ifnumber = inif;
}
```

请注意，在桥表已满容量的情况下，此实现采用简单策略 - 它无法添加新地址。回想一下，正确转发不需要桥表的完整性; 它只是优化了性能。如果表中有一些当前未使用的条目，它最终会超时并被删除，从而为新条目创建空间。另一种方法是在查找表格时调用某种缓存替换算法; 例如，我们可能会找到并删除具有最小TTL的条目以容纳新条目。

![img](https://book.systemsapproach.org/internetworking/figures/f03-10-9780123850591.png)带循环的扩展LAN。

### 生成树算法

前面的策略工作得很好，直到扩展的局域网中有一个循环，在这种情况下它以一种可怕的方式失败 - 帧可能永远地循环通过扩展的局域网。这在[图10](https://book.systemsapproach.org/internetworking/switching.html#elan3)中描绘的示例中很容易看出，其中，例如，桥B1，B4和B6形成环。假设数据包从以太网J进入网桥B4，并且目标地址是尚未进入任何网桥转发表的地址：B4将数据包的副本发送到以太网H和I.现在网桥B6将数据包转发到以太网G，其中B1会看到它并将其转发回以太网H; B4在其表中仍然没有这个目的地，因此它将数据包转发回以太网I和J.没有什么可以阻止这个循环无休止地重复，在B1，B4和B6之间的数据包循环。

为什么扩展的局域网会出现循环？一种可能性是网络由多个管理员管理，例如，因为它跨越组织中的多个部门。在这样的设置中，可能没有一个人知道网络的整个配置，这意味着可以在没有人知道的情况下添加关闭循环的桥。第二种更可能的情况是，故意将环路内置到网络中 - 以便在出现故障时提供冗余。毕竟，没有循环的网络只需要将一个链路故障分成两个独立的分区。

无论原因是什么，桥梁必须能够正确处理环路。通过使网桥运行分布式*生成树*算法来解决该问题。如果您认为扩展LAN由可能具有循环（循环）的图表表示，则生成树是此图的子图，其覆盖（跨越）所有顶点但不包含循环。也就是说，生成树保留原始图形的所有顶点但抛出一些边缘。例如， [图11](https://book.systemsapproach.org/internetworking/switching.html#graphs)显示了左侧的循环图和右侧可能有许多生成树之一。

![img](https://book.systemsapproach.org/internetworking/figures/f03-11-9780123850591.png)（a）循环图的例子; （b）相应的生成树。

The idea of a spanning tree is simple enough: It's a subset of the actual network topology that has no loops and that reaches all the LANs in the extended LAN. The hard part is how all of the bridges coordinate their decisions to arrive at a single view of the spanning tree. After all, one topology is typically able to be covered by multiple spanning trees. The answer lies in the spanning tree protocol, which we'll describe now.

生成树算法由Radia Perlman开发，然后在Digital Equipment Corporation开发，是由一组桥使用的协议，用于就特定扩展LAN的生成树达成一致。（LAN网桥的IEEE 802.1规范基于此算法。）实际上，这意味着每个网桥决定了它所在的端口，并且不愿意转发帧。从某种意义上说，通过从拓扑中删除端口，扩展LAN被缩减为非循环树。甚至有可能整个桥都不会参与转发帧，乍一看似乎有些奇怪。然而，该算法是动态的，这意味着如果某些网桥出现故障，网桥总是准备将自身重新配置为新的生成树，

> 将扩展LAN表示为抽象图有点尴尬。基本上，您让桥梁和LAN都对应于图形的顶点，端口对应于图形的边缘。但是，我们要为此图计算的生成树只需要跨越那些与网络对应的节点。对应于桥的节点可能与图的其余部分断开连接。这对应于通过算法移除将桥连接到各种网络的所有端口的情况。

生成树的主要思想是桥接器选择它们将转发帧的端口。该算法选择端口如下。每个桥都有唯一的标识符; 为了我们的目的，我们使用标签B1，B2，B3等。算法首先选择ID最小的桥作为生成树的根; 这次选举究竟如何发生如下所述。根网桥始终在所有端口上转发帧。接下来，每个网桥计算到根的最短路径，并记录其中哪个端口在此路径上。此端口也被选为桥接器的首选路径。最后，连接到给定LAN的所有桥接器都选择一个 *指定的*将负责将帧转发到根网桥的网桥。每个LAN的指定桥是最靠近根的桥。如果两个或多个网桥同样靠近根网，则网桥标识符用于断开连接，最小的ID获胜。当然，每个网桥都连接到多个LAN，因此它参与为其连接的每个LAN选择指定的网桥。实际上，这意味着每个网桥决定它是否是相对于每个端口的指定网桥。网桥在那些指定网桥的端口上转发帧。

![img](https://book.systemsapproach.org/internetworking/figures/f03-12-9780123850591.png)生成树，未选择某些端口。

[图12](https://book.systemsapproach.org/internetworking/switching.html#elan4)显示了与[图10](https://book.systemsapproach.org/internetworking/switching.html#elan3)中[所示](https://book.systemsapproach.org/internetworking/switching.html#elan3)的扩展LAN相对应的生成树。在此示例中，B1是根网桥，因为它具有最小的ID。请注意，B3和B5都连接到LAN A，但B5是指定的桥，因为它更接近根。类似地，B5和B7都连接到LAN B，但在这种情况下B5是指定的桥，因为它具有较小的ID; 两者距B1都相等。

虽然人类可以查看[图10中](https://book.systemsapproach.org/internetworking/switching.html#elan3)给出的扩展LAN 并根据上面给出的规则计算[图12中](https://book.systemsapproach.org/internetworking/switching.html#elan4)给出的生成树，但是扩展LAN中的网桥不具备能够查看整个网络的拓扑结构，更不用说窥视其他网桥以查看其ID。相反，网桥必须相互交换配置消息，然后根据这些消息确定它们是否是根或指定的桥。

具体来说，配置消息包含三条信息：

1. 发送消息的网桥的ID。
2. 发送桥认为是根桥的ID。
3. 以跳数衡量的距离，从发送桥到根桥。

每个网桥记录它在每个端口上看到的当前*最佳*配置消息（“最佳”定义如下），包括它从其他网桥接收的消息和它自己发送的消息。

最初，每个网桥都认为它是根，因此它在每个端口上发送一个配置消息，标识自己为根，并给出根到0的距离。在特定端口上接收配置消息时，桥接器检查该新消息是否优于为该端口记录的当前最佳配置消息。如果满足以下任何条件，则认为新配置消息*优于*当前记录的信息：

- 它标识ID较小的根。
- 它标识具有相同ID但距离较短的根。
- 根ID和距离相等，但发送桥的ID较小

如果新消息优于当前记录的信息，则网桥丢弃旧信息并保存新信息。但是，它首先将1加到距离到根目录字段，因为网桥比发送消息的网桥距离根更远一跳。

当网桥收到一条配置消息，表明它不是根网桥时 - 即来自网桥ID较小的网桥的消息 - 网桥自行停止生成配置消息，而只是在其他网桥之后才转发配置消息将1添加到距离字段。同样，当一个网桥收到一条配置消息，表明它不是该端口的指定网桥时 - 也就是说，来自网桥的消息更接近根或距离根更远但ID更小 - 网桥停止通过该端口发送配置消息。因此，当系统稳定时，只有根网桥仍在生成配置消息，而其他网桥仅通过它们是指定网桥的端口转发这些消息。在此刻，已经构建了生成树，并且所有网桥都对生成树使用哪些端口达成一致。只有那些端口可用于在扩展LAN中转发数据包。

让我们看一下如何使用一个例子。考虑如果电源刚刚恢复到容纳该网络的建筑物中，[图12中](https://book.systemsapproach.org/internetworking/switching.html#elan4)会发生什么 ，以便所有桥接器几乎同时启动。所有的桥梁都是从声称自己的根源开始的。我们表示来自节点X的配置消息，其中它声称距根节点Y的距离为（Y，d，X）。关注节点B3处的活动，一系列事件将展开如下：

1. B3接收（B2,0，B2）。
2. 由于2 <3，B3接受B2作为根。
3. B3在B2（0）广告的距离上加1，从而向B5发送（B2,1，B3）。
4. 同时，B2接受B1作为root，因为它具有较低的ID，并且它向B3发送（B1,1，B2）。
5. B5接受B1作为root并向B3发送（B1,1，B5）。
6. B3接受B1作为root，它注意到B2和B5都比根更接近根; 因此，B3停止在其两个接口上转发消息。

这使得B3没有选择两个端口，[如图12](https://book.systemsapproach.org/internetworking/switching.html#elan4)所示 。

即使在系统稳定后，根网桥也会定期继续发送配置消息，其他网桥继续转发这些消息，如前一段所述。如果特定网桥发生故障，下游网桥将不会收到这些配置消息，并且在等待一段指定的时间后，它们将再次声称是根，并且刚刚描述的算法将再次启动以选择新的根和新的指定桥梁。

需要注意的一件重要事情是，尽管算法能够在桥发生故障时重新配置生成树，但为了绕过拥塞的桥路由，它无法在备用路径上转发帧。

### 广播和组播

前面的讨论集中在桥接如何将单播帧从一个LAN转发到另一个LAN。由于网桥的目标是透明地将LAN扩展到多个网络，并且由于大多数LAN都支持广播和多播，因此网桥也必须支持这两个功能。广播很简单 - 每个网桥在每个活动（选定）端口上转发具有目的地广播地址的帧，而不是接收帧的端口。

多播可以以完全相同的方式实现，每个主机决定是否接受该消息。这正是在实践中所做的。但请注意，由于并非扩展LAN中的所有LAN都必须具有作为特定多播组成员的主机，因此可以做得更好。具体地，生成树算法可以扩展到修剪无需转发组播帧的网络。考虑由[图12中的](https://book.systemsapproach.org/internetworking/switching.html#elan4) LAN A上的主机发送给组M的帧。如果LAN J上没有属于组M的主机，则桥B4不需要通过该网络转发帧。另一方面，没有属于M组的LAN H上的主机并不一定意味着网桥B1可以避免将组播帧转发到LAN H上。这完全取决于是否在LAN I上存在组M的成员。 J.

给定网桥如何了解它是否应该在给定端口上转发多播帧？它通过观察通过该端口接收的*源*地址，了解桥接器是否应该通过特定端口转发单播帧的方式。当然，群体通常不是帧的来源，所以我们不得不作弊。特别地，作为组M的成员的每个主机必须周期性地在帧头的源字段中发送具有组M的地址的帧。该帧将具有作为其目的地址的桥的多播地址。

注意，尽管刚刚提出的组播扩展一度被提出，但它没有被广泛采用。相反，多播的实现方式与当今扩展LAN上的广播完全相同。

### 桥梁的局限性

刚刚描述的基于桥接的解决方案仅用于相当有限的设置 - 连接少数类似的LAN。当我们考虑规模和异质性问题时，桥梁的主要局限性变得明显。

在规模问题上，通过桥接连接多个局域网是不现实的，实际上*很少*通常意味着“数十个”。其中一个原因是生成树算法线性扩展; 也就是说，没有规定在扩展LAN上强加层次结构。第二个原因是网桥转发所有广播帧。虽然在有限设置（例如，部门）内的所有主机看到彼此的广播消息是合理的，但是更大环境中的所有主机（例如，大型公司或大学）不太可能希望必须是彼此的广播信息困扰着。换句话说，广播不扩展，因此扩展的LAN不扩展。

增加扩展LAN可扩展性的一种方法是 *虚拟LAN*（VLAN）。VLAN允许将单个扩展LAN划分为几个看似独立的LAN。为每个虚拟LAN分配一个标识符（有时称为*颜色*），如果两个段具有相同的标识符，则数据包只能从一个段传输到另一个段。这具有限制将接收任何给定广播分组的扩展LAN中的分段数量的效果。

![img](https://book.systemsapproach.org/internetworking/figures/f03-13-9780123850591.png)两个虚拟LAN共享一个共同的主干。

我们可以看到VLAN如何使用示例。[图13](https://book.systemsapproach.org/internetworking/switching.html#vlan)显示了四个不同LAN网段上的四台主机。在没有VLAN的情况下，来自任何主机的任何广播数据包都将到达所有其他主机。现在让我们假设我们将连接到主机W和X的段定义为在一个VLAN中，我们将其称为VLAN 100.我们还将连接到主机Y和Z的段定义为在VLAN 200中。为此，我们需要在网桥B1和B2的每个端口上配置VLAN ID。B1和B2之间的链路被认为是在两个VLAN中。

当主机X发送的数据包到达网桥B2时，网桥会观察到它来自配置为VLAN 100的端口。它在以太网报头和其有效负载之间插入一个VLAN报头。VLAN标头的有趣部分是VLAN ID; 在这种情况下，该ID设置为100.网桥现在应用其正常的规则转发到数据包，但额外的限制是数据包可能不会从不属于VLAN 100的接口发出。因此，在在这种情况下，数据包 - 甚至是广播数据包 - 从接口发送到主机Z，该主机Z在VLAN 200中。然而，该数据包被转发到桥B1，它遵循相同的规则，因此可以将数据包转发给主机W但不是主持Y.

VLAN的一个有吸引力的特性是可以在不移动任何线路或更改任何地址的情况下更改逻辑拓扑。例如，如果我们想要使连接到主机Z的段成为VLAN 100的一部分，从而使X，W和Z在同一个虚拟LAN上，那么我们只需要在桥上更改一个配置B2。

在异构性问题上，桥接在它们可以互连的网络类型中相当有限。特别是，网桥使用网络的帧头，因此只能支持具有完全相同的地址格式的网络。因此，网桥可用于将以太网连接到以太网，令牌环连接到令牌环，以及一个802.11网络连接到另一个网络。也可以在以太网和802.11网络之间架起一座桥，因为两个网络都支持相同的48位地址格式。但是，桥接器不容易推广到具有不同寻址格式的其他类型的网络，例如ATM。

尽管存在局限性，但网桥是完整网络图片中非常重要的一部分。它们的主要优点是它们允许多个LAN透明连接; 也就是说，网络可以连接而终端主机不必运行任何其他协议（或者甚至意识到）。一个潜在的例外是当主机预期在多播组中宣布其成员资格时。

但请注意，这种透明度可能很危险。如果主机或者更确切地说，在该主机上运行的应用程序和传输协议是在假设它在单个LAN上运行的情况下编程的，那么在源主机和目标主机之间插入桥接器会产生意想不到的后果。例如，如果桥梁变得拥挤，则可能必须丢帧; 相比之下，单个以太网很少丢帧。作为另一个例子，扩展LAN上的任何一对主机之间的等待时间变得更大并且变化更大; 相比之下，单个以太网的物理限制使得延迟既小又可预测。作为最后一个例子，有可能（尽管不太可能）帧将在扩展LAN中重新排序; 相反，帧顺序永远不会在单个以太网上进行。最重要的是，假设它将在单个以太网段上运行，设计网络软件永远不会安全。桥梁发生了。

内容[数据报](https://book.systemsapproach.org/internetworking/switching.html#datagrams)[虚电路交换](https://book.systemsapproach.org/internetworking/switching.html#virtual-circuit-switching)[源路由](https://book.systemsapproach.org/internetworking/switching.html#source-routing)[网桥和L2交换机](https://book.systemsapproach.org/internetworking/switching.html#bridges-and-l2-switches)





# [3.2基本网络互联](https://book.systemsapproach.org/)

# 3.2基本网络互联

在上一节中，我们看到可以使用网桥和LAN交换机构建相当大的LAN，但这种方法在扩展和处理异构性方面的能力有限。在本节中，我们将探讨超越桥接网络限制的一些方法，使我们能够以合理有效的路由构建大型，高度异构的网络。我们将此类网络称为 *互联网络。*我们将在下一章继续讨论如何构建真正的全球互联网络，但现在我们将探索基础知识。我们首先要仔细考虑*互联网*这个词的 含义。

## 什么是网络工作？

我们使用术语“ *互联网络”*，或者有时只使用带有小写字母*i的**互联网*，来指代互连的任意网络集合，以提供某种主机到主机的数据包传送服务。例如，具有许多站点的公司可以通过将其不同站点的LAN与从电话公司租用的点对点链路互连来构建私有互联网络。当我们谈论现在大量网络连接的广泛使用的全球互联网络时，我们将其称为具有大写*I*的*互联网**。*为了与本书的第一原则方法保持一致，我们主要希望您了解“小写的原则， *我*“网络互联，但我们用来自”大*一号*“互联网的真实世界的例子来说明这些想法。

另一个令人困惑的术语是网络，子网和互联网络之间的差异。我们将完全避免子网（或子网），直到后面的部分。目前，我们使用*网络*来表示上一节和前一章中描述的那种直接连接或交换网络。这种网络使用一种技术，例如802.11或以太网。一个*互联网络*是这种网络的互连集合。有时，为了避免歧义，我们将我们作为*物理*网络互连的底层网络称为。互联网是*合乎逻辑的*网络由一系列物理网络构成。在这种情况下，通过网桥或交换机连接的以太网段的集合仍将被视为单个网络。

![img](https://book.systemsapproach.org/internetworking/figures/f03-14-9780123850591.png)一个简单的互联网络。H表示主机，R表示路由器。

[图1](https://book.systemsapproach.org/internetworking/basic-ip.html#inet)显示了一个示例互联网络。互联网络通常被称为“网络网络”，因为它由许多较小的网络组成。在此图中，我们看到了以太网，无线网络和点对点链路。这些都是单一技术网络。互连网络的节点称为*路由器*。它们有时也被称为*网关*，但由于这个术语有其他几个含义，我们将使用限制在路由器中。

![img](https://book.systemsapproach.org/internetworking/figures/f03-15-9780123850591.png)一个简单的互联网络，显示了上图中用于连接H5和H8的协议层。ETH是通过以太网运行的协议。

该*互联网协议*是目前用于构建可扩展的，异构互联网络的重要工具。它最初被称为Kahn-Cerf协议的发明者。考虑IP的一种方法是它在一组网络中的所有节点（主机和路由器）上运行，并定义允许这些节点和网络作为单个逻辑互联网络运行的基础设施。例如， [图2](https://book.systemsapproach.org/internetworking/basic-ip.html#ip-graph)显示了主机H5和H8如何通过[图1中](https://book.systemsapproach.org/internetworking/basic-ip.html#inet)的互联网逻辑连接，包括在每个节点上运行的协议图。请注意，较高级别的协议（如TCP和UDP）通常在主机上的IP之上运行。

本章和下一章的其余部分涉及知识产权的各个方面。虽然建立一个不使用IP的互联网络当然是可能的，事实上，在互联网发展的早期，有其他解决方案 - 由于互联网的规模，IP是最有趣的研究案例。换句话说，只有IP互联网才真正面临规模问题。因此，它提供了可扩展的网络协作协议的最佳案例研究。

## 服务模式

构建互联网络时，一个好的起点是定义其 *服务模型*，即您要提供的主机到主机服务。定义互联网络服务模型的主要问题是，只有在可以通过某种方式在每个底层物理网络上提供此服务时，我们才能提供主机到主机服务。例如，如果存在可以任意延迟数据包的底层网络技术，那么决定我们的互联网服务模型将在1毫秒或更短的时间内提供每个数据包的保证传输将是不利的。因此，用于定义IP服务模型的理念是使其足够低，以至于几乎任何可能出现在互联网络中的网络技术都能够提供必要的服务。

IP服务模型可以被认为具有两个部分：寻址方案，其提供识别互联网络中的所有主机的方式，以及数据报（无连接）数据传送模型。这种服务模型有时被称为*尽力而为，*因为尽管IP尽一切努力提供数据报，但它并不能保证。我们暂时推迟讨论寻址方案，首先看一下数据传输模型。

### 数据报交付

IP数据报是Internet协议的基础。回想一下前面的部分，数据报是一种恰好通过网络以无连接方式发送的数据包。每个数据报都携带足够的信息，让网络将数据包转发到正确的目的地; 当数据包到达时，不需要任何先进的设置机制来告诉网络该做什么。您只需发送它，网络就会尽最大努力将其送到目的地。“尽力而为”部分意味着如果出现问题并且数据包丢失，损坏，错误传送或以任何方式无法到达其预定目的地，网络什么都不做 - 它尽了最大的努力，就是这样。必须做。它没有尝试从失败中恢复。 服务。

尽力而为，无连接的服务是关于您可以通过互联网络提出的最简单的服务，这是一个很大的优势。例如，如果您通过提供可靠服务的网络提供尽力服务，那么这很好 - 您最终会得到一个尽力而为的服务。另一方面，如果您在不可靠的网络上拥有可靠的服务模型，则必须在路由器中添加许多额外的功能，以弥补底层网络的不足。保持路由器尽可能简单是IP的最初设计目标之一。

知识产权“战胜任何事物”的能力经常被认为是其最重要的特征之一。值得注意的是，当IP发明时，许多IP运行的技术并不存在。到目前为止，还没有发明任何网络技术已被证明对IP来说太奇怪了; 原则上，IP可以在使用载体鸽传输消息的网络上运行。

尽力而为的交付并不仅仅意味着数据包可能会丢失。有时它们可能无法按顺序交付，有时同一个数据包可以多次交付。在IP之上运行的更高级协议或应用程序需要了解所有这些可能的故障模式。

### 包格式

显然，IP服务模型的关键部分是可以携带的数据包类型。与大多数数据包一样，IP数据报由一个标头后跟多个字节的数据组成。标题的格式[如图3](https://book.systemsapproach.org/internetworking/basic-ip.html#iphead)所示。请注意，我们采用了不同的表示数据包的方式，而不是前面章节中使用的方式。这是因为网络互联层及其以上的数据包格式，我们将在接下来的几章中集中注意力，几乎总是设计为在32位边界上对齐，以简化在软件中处理它们的任务。因此，表示它们的常用方法（例如，在Internet请求注释中使用）是将它们绘制为一系列32位字。首字是首先发送的字，每个字的最左边字节是首先发送的字。在此表示中，您可以轻松识别8位长的倍数字段。在字段不是8位的偶数倍的奇怪场合，

![img](https://book.systemsapproach.org/internetworking/figures/f03-16-9780123850591.png)IPv4包头。

查看IP头中的每个字段，我们看到尽力而为数据报传递的“简单”模型仍然具有一些微妙的功能。该 `Version`字段指定IP的版本。仍然假设的IP版本是4，通常称为*IPv4*。请注意，将此字段放在数据报的开头，可以轻松地在后续版本中重新定义数据包格式中的其他所有内容。标题处理软件通过查看版本开始，然后分支以根据适当的格式处理数据包的其余部分。下一个字段，`HLen`以32位字指定标头的长度。当没有选项时（大多数情况下），标题长度为5个字（20个字节）。8位`TOS`（服务类型）字段多年来有许多不同的定义，但其基本功能是允许根据应用程序需求对数据包进行不同的处理。例如，该`TOS`值可以确定是否应将数据包放置在接收低延迟的特殊队列中。

标头的下16位包含`Length`数据报的内容，包括标头。与`HLen`字段不同，`Length`字段计算字节而不是字。因此，IP数据报的最大大小为65,535字节。但是，运行IP的物理网络可能不支持这样的长数据包。因此，IP支持碎片和重组过程。标题的第二个单词包含有关碎片的信息，其使用的详细信息在下面标题为“碎片和重组”的部分中介绍。

继续前进到标题的第三个字，下一个字节是`TTL` （生存时间）字段。它的名字反映了它的历史意义，而不是它今天常用的方式。该字段的目的是捕获已经在路由循环中传播的数据包并丢弃它们，而不是让它们无限期地消耗资源。最初， `TTL`设置为允许数据包生效的特定秒数，沿路径的路由器将减少该字段直到达到0.但是，因为数据包很少长达1秒在路由器中，路由器并不都可以访问公共时钟，大多数路由器只是减少了`TTL`他们转发数据包时为1。因此，它变得更像是一个跳数而不是一个计时器，这仍然是一个很好的方法来捕获卡在路由循环中的数据包。一个微妙之处在于发送主机在该字段的初始设置中：将其设置得太高并且数据包在丢弃之前可以相当多地循环; 设置得太低，可能无法到达目的地。值64是当前默认值。

该`Protocol`字段只是一个解复用密钥，用于标识此IP数据包应传递到的更高级别协议。存在为TCP（传输控制协议-6），UDP（用户数据报协议-17）以及可能位于协议图中的IP之上的许多其他协议定义的值。

在`Checksum`通过考虑整个IP报头为16位字的序列，将它们添加了使用的补运算，并采取的那些的结果的补码计算。因此，如果报头中的任何位在传输中被破坏，则在收到数据包时校验和将不包含正确的值。由于损坏的头部可能包含目标地址中的错误 - 因此可能已经错误传递 - 丢弃任何未通过校验和的数据包是有意义的。应该注意的是，这种类型的校验和不具有与CRC相同的强错误检测属性，但是在软件中计算起来要容易得多。

标头中的最后两个必填字段是`SourceAddr`和 `DestinationAddr`数据包。后者是数据报传送的关键：每个数据包都包含其预定目的地的完整地址，以便可以在每个路由器上做出转发决定。需要源地址以允许收件人决定是否要接受数据包并使其能够回复。IP地址将在后面的部分讨论 - 目前，重要的是要知道IP定义了自己的全局地址空间，与其运行的物理网络无关。正如我们将要看到的，这是支持异质性的关键之一。

最后，标题末尾可能有许多选项。可以通过检查标题长度（`HLen`）字段来确定选项的存在或不存在。虽然很少使用选项，但完整的IP实现必须处理所有选项。

### 碎片和重组

在异构网络集合上提供统一的主机到主机服务模型的问题之一是每个网络技术倾向于对数据包的大小有自己的想法。例如，经典以太网可以接受长达1500字节的数据包，但是现代变体可以提供更大（巨型）数据包，最多可传输9000字节的有效负载。这为IP服务模型留下了两个选择：确保所有IP数据报都足够小，以适应任何网络技术中的一个数据包，或者提供一种方法，当数据包太大而无法覆盖时，可以将数据包分段并重新组合。给定网络技术。后者证明是一个很好的选择，特别是当你考虑到新的网络技术总是出现这种事实，并且IP需要在所有这些技术上运行时; 这将使得很难在数据报大小上选择适当小的界限。这也意味着主机不会发送不必要的小数据包，这会浪费带宽并消耗处理资源，因为每个字节的数据发送需要更多的报头。

这里的中心思想是每种网络类型都有一个*最大传输单元*（MTU），它是一个帧中可以携带的最大IP数据报。请注意，此值小于该网络上的最大数据包大小，因为IP数据报需要适合链路层帧的 *有效负载*。

> 在ATM网络中，幸运的是，MTU比单个小区大得多，因为ATM具有其自己的分段机制。ATM中的链路层帧称为*汇聚 - 子层协议数据单元*（CS-PDU）。

因此，当主机发送IP数据报时，它可以选择它想要的任何大小。合理的选择是主机直接连接的网络的MTU。然后，仅当到目的地的路径包括具有较小MTU的网络时，才需要分段。但是，如果位于IP之上的传输协议为IP提供的数据包大于本地MTU，则源主机必须将其分段。

当路由器接收到想要通过小于接收数据报的MTU的网络转发数据报时，通常会在路由器中发生分段。要使这些片段能够在接收主机上重新组装，它们在`Ident` 字段中都带有相同的标识符。该标识符由发送主机选择，并且在可能在某个合理的时间段内从该源到达目的地的所有数据报中是唯一的。由于原始数据报的所有片段都包含此标识符，因此重组主机将能够识别出一起出现的那些片段。如果所有碎片都没有到达接收主机，则主机放弃重组过程并丢弃到达的碎片。IP不会尝试从丢失的片段中恢复。

![img](https://book.systemsapproach.org/internetworking/figures/f03-17-9780123850591.png)穿过前面图中的物理网络序列的IP数据报。

要了解这一切意味着什么，请考虑当主机H5在[图1](https://book.systemsapproach.org/internetworking/basic-ip.html#inet)所示的示例Internet中向主机H8发送数据报时会发生什么。假设两个以太网和802.11网络的MTU为1500字节，点对点网络为532字节，那么从H5发送的1420字节数据报（20字节IP报头加上1400字节数据）它通过802.11网络和第一个没有分段的以太网，但必须在路由器R2上分成三个数据报。然后，路由器R3将这三个片段通过第二个以太网转发到目标主机。这种情况[如图4所示](https://book.systemsapproach.org/internetworking/basic-ip.html#frag)。这个数字也有助于强调两个重点：

1. 每个片段本身是一个独立的IP数据报，它通过一系列物理网络传输，独立于其他片段。
2. 每个IP数据报都针对其传输的每个物理网络进行重新封装。

![img](https://book.systemsapproach.org/internetworking/figures/f03-18-9780123850591.png)IP分片中使用的标头字段：（a）未分段的数据包; （b）碎片包。

通过查看每个数据报的头字段可以详细了解分段过程，[如图5所示](https://book.systemsapproach.org/internetworking/basic-ip.html#fragment)。顶部显示的未分段数据包具有1400字节的数据和20字节的IP标头。当数据包到达具有532字节MTU的路由器R2时，必须对其进行分段。5字节的MTU在20字节的IP报头之后留下512字节的数据，因此第一个片段包含512字节的数据。路由器在`Flags` 字段中设置M位（参见[图3](https://book.systemsapproach.org/internetworking/basic-ip.html#iphead)），这意味着要跟随更多片段，并将其设置`Offset`为0，因为此片段包含原始数据报的第一部分。第二个片段中携带的数据以原始数据的第513个字节开始，因此`Offset`此标头中的字段设置为64，即512/8。为什么划分8？因为IP的设计者决定碎片应该总是发生在8字节边界上，这意味着该`Offset`字段计数8字节块，而不是字节。（我们将它作为练习让你弄清楚为什么做出这个设计决定。）第三个片段包含最后376个字节的数据，现在偏移量为2\倍× 512/8 = 128.由于这是最后一个片段，因此未设置M位。

观察到碎片化过程以这样的方式完成：如果片段到达具有更小MTU的另一个网络，则可以重复碎片化过程。碎片产生较小的有效IP数据报，可以在接收时轻松地重新组合成原始数据报，而与其到达顺序无关。重新组装在接收主机上完成，而不是在每个路由器上完成。

IP重组远非一个简单的过程。例如，如果单个片段丢失，接收器仍将尝试重新组装数据报，并且最终将放弃并且必须垃圾收集用于执行失败重组的资源。让主机不必要地占用资源可能是拒绝服务攻击的基础。

出于这个原因，IP碎片通常被认为是一件好事。现在强烈建议主机执行“路径MTU发现”，通过发送足够小的数据包以便从发送方到接收方的路径中具有最小MTU的链路来避免分段。

## 全球地址

在上面对IP服务模型的讨论中，我们提到它提供的一个问题是寻址方案。毕竟，如果您希望能够将数据发送到任何网络上的任何主机，则需要一种识别所有主机的方法。因此，我们需要一种全局寻址方案 - 其中没有两个主机具有相同的地址。全局唯一性是应该在寻址方案中提供的第一个属性。

以太网地址是全球唯一的，但仅靠这一点并不足以满足大型互联网络中的寻址方案。以太网地址也是*扁平的*，这意味着它们没有结构，并且很少提供路由协议的线索。（实际上，以太网地址确实具有用于*分配*目的的结构- 前24位标识制造商 - 但这不会为路由协议提供有用的信息，因为此结构与网络拓扑无关。）相反，IP地址是*分层的*，我们的意思是它们由几个部分组成，这些部分对应于互联网络中的某种层次结构。具体而言，IP地址由两部分组成，通常称为*网络*部分和*主持人*部分。对于互联网而言，这是一个相当合理的结构，互联网由许多互连的网络组成。IP地址的网络部分标识主机所连接的网络; 连接到同一网络的所有主机在其IP地址中具有相同的网络部分。然后，主机部分在该特定网络上唯一地标识每个主机。因此，在[图1](https://book.systemsapproach.org/internetworking/basic-ip.html#inet)的简单互联网络中，例如，网络1上的主机的地址将具有相同的网络部分和不同的主机部分。

请注意，[图1](https://book.systemsapproach.org/internetworking/basic-ip.html#inet)中的路由器连接到两个网络。他们需要在每个网络上都有一个地址，每个接口一个地址。例如，位于无线网络和以太网之间的路由器R1在到无线网络的接口上具有IP地址，其网络部分与该网络上的所有主机相同。它还在以太网接口上具有IP地址，该IP地址与该以太网上的主机具有相同的网络部分。因此，考虑到路由器可能被实现为具有两个网络接口的主机，将IP地址视为属于接口而不是主机更为精确。

现在，这些分层地址是什么样的？与其他形式的分层地址不同，这两个部分的大小对于所有地址都不相同。最初，IP地址分为三个不同的类，[如图6](https://book.systemsapproach.org/internetworking/basic-ip.html#class)所示，每个类定义了不同大小的网络和主机部分。（还有D类地址指定当前未使用的多播组和E类地址。）在所有情况下，地址长度为32位。

IP地址的类别在最重要的几位中标识。如果第一位为0，则它是A类地址。如果第一位是1而第二位是0，则它是B类地址。如果前两位是1而第三位是0，则它是C类地址。因此，在大约40亿个可能的IP地址中，一半是A类，四分之一是B类，八分之一是C类。每个类为地址的网络部分分配一定数量的比特，其余为主持人部分。A类网络有7位用于网络部分，24位用于主机部分，这意味着只能有126个A类网络（值0和127是保留的），但每个网络最多可容纳2个^ {24}2 4 - 2（约1600万）的主机（再次，有两个保留值）。B类地址为网络分配14位，为主机分配16位，这意味着每个B类网络可为65,534个主机分配空间。最后，C类地址主机只有8位，网络部分只有21位。因此，C类网络只能有256个唯一的主机标识符，这意味着只有254个连接的主机（一个主机标识符255，保留用于广播，0不是有效的主机号）。但是，寻址方案支持2^ {21}2个1 C类网络。

![img](https://book.systemsapproach.org/internetworking/figures/f03-19-9780123850591.png)IP地址：（a）A类; （b）B类; （c）C班

从表面上看，这种寻址方案具有很大的灵活性，可以相当有效地容纳大小不同的网络。最初的想法是，互联网将由少量广域网（这些是A类网络），适度数量的站点（校园）大小的网络（这些将是B类网络）和大型网络组成。局域网的数量（这些将是C类网络）。然而，事实证明它不够灵活，我们马上就会看到。今天，IP地址通常是“无类别的”; 详细说明如下。

在我们研究如何使用IP地址之前，先了解一些实际问题（例如如何将其写下来）是有帮助的。按照惯例，IP地址被写为由点分隔的四个*十进制*整数。每个整数表示地址的1个字节中包含的十进制值，从最重要的开始。例如，键入该句子的计算机的地址是`171.69.210.245`。

重要的是不要将IP地址与Internet域名混淆，因为Internet域名也是分层的。域名往往是由点分隔的ASCII字符串，例如`cs.princeton.edu`。IP地址的重要之处在于它们是IP数据包报头中携带的内容，它是IP路由器中用于做出转发决策的那些地址。

## IP中的数据报转发

我们现在已经准备好了解IP路由器在互联网络中转发数据报的基本机制。回想一下前面的部分，*转发*是从输入获取数据包并在适当的输出上发送出去的过程，而*路由*是建立表的过程，允许确定数据包的正确输出。这里的讨论侧重于转发; 我们将在后面的部分中介绍路由。

在讨论IP数据报转发时要记住的要点如下：

- 每个IP数据报都包含目标主机的IP地址。
- IP地址的网络部分唯一地标识作为较大因特网的一部分的单个物理网络。
- 共享其地址的相同网络部分的所有主机和路由器连接到同一物理网络，因此可以通过在该网络上发送帧来彼此通信。
- 作为因特网一部分的每个物理网络至少具有一个路由器，根据定义，该路由器还连接到至少一个其他物理网络; 此路由器可以与任一网络上的主机或路由器交换数据包。

因此，可以通过以下方式处理转发IP数据报。数据报从源主机发送到目标主机，可能沿途经过多个路由器。任何节点（无论是主机还是路由器）都首先尝试确定它是否连接到与目标相同的物理网络。为此，它将目标地址的网络部分与其每个网络接口的地址的网络部分进行比较。（主机通常只有一个接口，而路由器通常有两个或更多，因为它们通常连接到两个或多个网络。）如果匹配发生，则表示目标与接口位于同一物理网络上，并且数据包可以通过该网络直接传送。后面的部分将介绍此过程的一些细节。

如果节点未连接到与目标节点相同的物理网络，则需要将数据报发送到路由器。通常，每个节点都可以选择多个路由器，因此需要选择最好的路由器，或者至少有一个能够使数据报更接近目的地的路由器。它选择的路由器称为*下一跳*路由器。路由器通过查询其转发表找到正确的下一跳。转发表在概念上只是一个列表`(NetworkNum, NextHop)`对。（正如我们将在下面看到的，实际中转发表通常包含与下一跳相关的一些附加信息。）通常，如果表中的所有条目都与目标的网络号匹配，则还使用默认路由器。对于主机，拥有默认路由器并没有其他任何东西是完全可以接受的 - 这意味着发往不在发送主机所连接的物理网络上的主机的所有数据报将通过默认路由器发送出去。

我们可以用以下方式描述数据报转发算法：

```pseudo
if (NetworkNum of destination = NetworkNum of one of my interfaces) then
    deliver packet to destination over that interface
else
    if (NetworkNum of destination is in my forwarding table) then
        deliver packet to NextHop router
    else
        deliver packet to default router
```

对于只有一个接口且转发表中只有默认路由器的主机，这简化为

```pseudo
if (NetworkNum of destination = my NetworkNum) then
    deliver packet to destination directly
else
    deliver packet to default router
```

让我们看看它如何在[图1](https://book.systemsapproach.org/internetworking/basic-ip.html#inet)的示例网络中工作 。首先，假设H1想要将数据报发送到H2。由于它们位于同一物理网络上，因此H1和H2在其IP地址中具有相同的网络号。因此，H1推断它可以通过以太网将数据报直接传送到H2。需要解决的一个问题是H1如何找到H2的正确以太网地址 - 后面部分中描述的解析机制解决了这个问题。

现在假设H5想要向H8发送数据报。由于这些主机位于不同的物理网络上，因此它们具有不同的网络号，因此H5推断它需要将数据报发送到路由器。R1是唯一的选择 - 默认路由器 - 因此H1通过无线网络将数据报发送到R1。同样，R1知道它不能直接向H8传送数据报，因为R1的接口都不和H8在同一网络上。假设R1的默认路由器是R2; R1然后通过以太网将数据报发送到R2。假设R2具有[表1](https://book.systemsapproach.org/internetworking/basic-ip.html#ipfwdtab)中所示的转发表 ，它会查找H8的网络号（网络4），并通过点对点网络将数据报转发到R3。最后，R3由于与H8在同一网络上，因此将数据报直接转发给H8。



路由器R2的转发表。

| NetworkNum | 力宏 |
| :--------: | :--: |
|     1      |  R1  |
|     4      |  R3  |



路由器R2的完整转发表。

| NetworkNum | 力宏  |
| :--------: | :---: |
|     1      |  R1   |
|     2      | 界面1 |
|     3      | 接口0 |
|     4      |  R3   |

请注意，可以在转发表中包含有关直连网络的信息。例如，我们可以将路由器R2的网络接口标记为点对点链路（网络3）的接口0和以太网（网络2）的接口1。然后R2将具有[表2](https://book.systemsapproach.org/internetworking/basic-ip.html#tab5.3)中所示的转发表 。

因此，对于R2在数据包中遇到的任何网络号，它都知道该怎么做。该网络直接连接到R2，在这种情况下，数据包可以通过该网络传送到其目的地，或者可以通过R2可以通过它所连接的网络到达的某个下一跳路由器来访问网络。在任何一种情况下，R2都将使用ARP（如下所述）来查找接下来要向其发送数据包的节点的MAC地址。

R2使用的转发表非常简单，可以手动配置。但是，通常这些表格更复杂，并且可以通过运行路由协议来构建，例如后面部分中描述的路由协议。还要注意，在实践中，网络号通常更长（例如，128.96）。

我们现在可以看到分层寻址 - 将地址分成网络和主机部分 - 如何提高了大型网络的可扩展性。路由器现在包含仅列出一组网络号而不是网络中所有节点的转发表。在我们的简单示例中，这意味着R2可以在四条目表中存储到达网络中所有主机（其中有八个）所需的信息。即使每个物理网络上有100个主机，R2仍然只需要相同的四个条目。这是实现可扩展性的良好的第一步（尽管绝不是最后一步）。



重点外卖



这说明了构建可伸缩网络的最重要原则之一：要实现可伸缩性，您需要减少存储在每个节点中以及在节点之间交换的信息量。最常见的方法是*分层聚合*。IP引入了两级层次结构，网络位于顶层，节点位于底层。我们通过让路由器只处理到达正确的网络来汇总信息; 路由器需要将数据报传递到给定网络上的任何节点的信息由单个聚合信息表示。

## 子网和无类别寻址

IP地址的最初意图是网络部分将唯一地标识一个物理网络。事实证明，这种方法有一些缺点。想象一下，一个拥有大量内部网络并决定连接到互联网的大型校园。对于每个网络，无论多小，网站至少需要一个C类网络地址。更糟糕的是，对于任何拥有超过255个主机的网络，他们需要一个B类地址。这可能看起来不是什么大问题，事实上并非当互联网首次设想时，但只有有限数量的网络号码，并且B类地址远远少于C类。B类地址往往需求量特别高，因为您永远不知道您的网络是否可能超过255个节点，因此，从一开始就使用B类地址比在C类网络上用完房间时重新编号每个主机更容易。我们在这里观察到的问题是地址分配效率低下：具有两个节点的网络使用整个C类网络地址，从而浪费了253个完全有用的地址; B类网络略多于255个主机，浪费超过64,000个地址。

因此，为每个物理网络分配一个网络号，可能比我们想要的更快地耗尽IP地址空间。虽然我们需要连接超过40亿个主机来使用所有有效地址，但我们只需要连接2^ {14}1 4的地址空间的那部分之前（约16000）B类网络耗尽。因此，我们希望找到一些更有效地使用网络号码的方法。

分配许多网络号码有另一个缺点，当您考虑路由时会变得明显。回想一下，参与路由协议的节点中存储的状态量与其他节点的数量成正比，并且因特网中的路由包括构建转发表，该转发表告诉路由器如何到达不同的网络。因此，使用的网络号越多，转发表就越大。大型转发表会增加路由器的成本，对于给定技术，它们搜索的速度可能比较小的表更慢，因此会降低路由器的性能。这为仔细分配网络号码提供了另一个动机。

*子网划分*是减少分配的网络总数的第一步。我们的想法是获取单个IP网络号，并将具有该网络号的IP地址分配给多个物理网络，这些物理网络现在称为*子网*。要使这项工作需要做几件事。首先，子网应该彼此接近。这是因为从互联网的一个遥远的地方来看，它们看起来都像一个网络，它们之间只有一个网络号。这意味着路由器只能选择一条路由到达任何子网，因此它们最好都处于相同的总体方向。使用子网划分的完美情况是拥有许多物理网络的大型园区或公司。从校园外部，到校园内任何子网所需要知道的只是校园连接到互联网其他部分的地方。这通常是单点，因此转发表中的一个条目就足够了。即使校园连接到互联网的其他部分有多个点，

通过该单个网络数目可以多个网络之间共享的机制涉及配置上与每个子网的所有节点*子网掩码*。使用简单的IP地址，同一网络上的所有主机必须具有相同的网络号。子网掩码使我们能够引入*子网号* ; 同一物理网络上的所有主机将具有相同的子网号，这意味着主机可能位于不同的物理网络上但共享一个网络号。这个概念[如图7所示](https://book.systemsapproach.org/internetworking/basic-ip.html#subaddr)。

![img](https://book.systemsapproach.org/internetworking/figures/f03-20-9780123850591.png)子网寻址。

子网对主机的意义在于它现在配置了与其连接的子网的IP地址和子网掩码。例如，[图8中的](https://book.systemsapproach.org/internetworking/basic-ip.html#subnet)主机H1 配置地址为128.96.34.15，子网掩码为255.255.255.128。（给定子网上的所有主机都配置了相同的掩码;也就是说，每个子网只有一个子网掩码。）这两个数字的按位AND定义了主机和同一子网上所有其他主机的子网号。在这种情况下，128.96.34.15 AND 255.255.255.128等于128.96.34.0，因此这是图中最顶层子网的子网号。

![img](https://book.systemsapproach.org/internetworking/figures/f03-21-9780123850591.png)子网划分的一个例子。

当主机想要将数据包发送到某个IP地址时，它首先要做的是在它自己的子网掩码和目标IP地址之间执行按位AND。如果结果等于发送主机的子网号，则它知道目标主机位于同一子网上，并且数据包可以直接通过子网传送。如果结果不相等，则需要将数据包发送到路由器以转发到另一个子网。例如，如果H1发送到H2，则H1将其子网掩码（255.255.255.128）与H2（128.96.34.139）的地址进行AND运算以获得128.96.34.128。这与H1（128.96.34.0）的子网号不匹配，因此H1知道H2位于不同的子网上。由于H1无法直接通过子网将数据包传送到H2，因此它会将数据包发送到其默认路由器R1。

当我们引入子网时，路由器的转发表也会略有变化。回想一下，我们之前有一个转发表，其中包含表单的条目`(NetworkNum, NextHop)`。为了支持子网划分，该表现在必须保存表单的条目 `(SubnetNumber, SubnetMask, NextHop)`。为了在表中找到正确的条目，路由器将数据包的目的地地址`SubnetMask`依次与每个条目进行对比; 如果结果与`SubnetNumber`条目匹配 ，那么这是正确的条目，它将数据包转发到指示的下一跳路由器。在[图8](https://book.systemsapproach.org/internetworking/basic-ip.html#subnet)的示例网络中，路由器R1将具有[表2中](https://book.systemsapproach.org/internetworking/basic-ip.html#subnettab)所示的条目。



使用子网划分转发表的示例。

| SubnetNumber  | 子网掩码        | 力宏  |
| :------------ | :-------------- | :---- |
| 128.96.34.0   | 255.255.255.128 | 接口0 |
| 128.96.34.128 | 255.255.255.128 | 界面1 |
| 128.96.33.0   | 255.255.255.0   | R2    |

继续将H1发送到H2的数据报示例，R1将AND H2的地址（128.96.34.139）与第一个条目的子网掩码（255.255.255.128）进行比较，并将结果（128.96.34.128）与网络号进行比较该条目（128.96.34.0）。由于这不匹配，因此会进入下一个条目。这次匹配确实发生，因此R1使用接口1将数据报传送到H2，接口1是与H2连接到同一网络的接口。

我们现在可以通过以下方式描述数据报转发算法：

```pseudo
D = destination IP address
for each forwarding table entry (SubnetNumber, SubnetMask, NextHop)
    D1 = SubnetMask & D
    if D1 = SubnetNumber
        if NextHop is an interface
            deliver datagram directly to destination
        else
            deliver datagram to NextHop (a router)
```

虽然在此示例中未显示，但默认路由通常将包含在表中，并且如果未找到显式匹配则将使用该路由。请注意，该算法的一个简单实现 - 一个涉及目标地址的重复AND与每次可能没有不同的子网掩码，以及线性表搜索 - 将是非常低效的。

子网划分的一个重要结果是，互联网的不同部分以不同的方式看待世界。从我们假设的校园外部，路由器可以看到一个网络。在上面的示例中，校园外的路由器将 [图8](https://book.systemsapproach.org/internetworking/basic-ip.html#subnet)中的网络集合视为网络128.96，并且它们在转发表中保留一个条目以告知它们如何到达它。但是，园区内的路由器需要能够将数据包路由到正确的子网。因此，并非互联网的所有部分都看到完全相同的路由信息。这是路由信息*聚合*的一个示例，这是路由系统扩展的基础。下一节将介绍如何将聚合转移到另一个级别。

### 无类别寻址

子网有一个对应物，有时称为*超网*，但通常称为*无类域间路由*或CIDR，发音为“苹果酒”。CIDR通过基本上完全取消地址类，将子网理念理解为其逻辑结论。为什么单独子网不足够？实质上，子网划分只允许我们在多个子网之间拆分有类地址，而CIDR允许我们将几个有类地址合并为一个“超网”。这进一步解决了上面提到的地址空间低效问题，并且以防止路由系统过载的方式这样做。

要了解路由系统的地址空间效率和可扩展性问题是如何耦合的，请考虑其网络上有256个主机的公司的假设情况。这对于C类地址来说有点太多了，所以你很想分配一个B类。但是，使用一块可以寻址65535到256个主机的地址空间的效率只有256 / 65,535 = 0.39％ 。尽管子网可以帮助我们仔细分配地址，但它并没有解决任何拥有超过255个主机的组织，或者最终拥有那么多组织的组织想要一个B类地址的事实。

处理此问题的第一种方法是拒绝向任何请求提供B类地址的组织提供B类地址，除非他们能够显示需要接近64K地址的东西，而是给他们一个适当数量的C类地址。覆盖预期的主机数量。由于我们现在一次分配256个地址块的地址空间，我们可以更准确地将消耗的地址空间量与组织的大小相匹配。对于拥有至少256个主机的任何组织，我们可以保证地址利用率至少为50％，通常更多。

> 即使您可以证明B类网络号码的请求是合理的，也不要打扰。他们都说的都是。

然而，该解决方案提出了至少同样严重的问题：路由器的过多存储要求。例如，如果一个站点分配了16个C类网络号，这意味着每个Internet骨干路由器在其路由表中需要16个条目来将数据包定向到该站点。即使每个网络的路径相同，也是如此。如果我们为站点分配了B类地址，则相同的路由信息可以存储在一个表条目中。但是，我们的地址分配效率只有6\倍× 255 / 65,536 = 6.2％。

因此，CIDR试图平衡希望最小化路由器需要知道的路由数量与有效分发地址的需求。为此，CIDR帮助我们*聚合*路线。也就是说，它允许我们在转发表中使用单个条目来告诉我们如何到达许多不同的网络。如上所述，它通过打破地址类之间的刚性边界来实现这一点。要了解其工作原理，请考虑我们的假设组织，其中包含16个C类网络号。我们可以分发一系列*连续的* C类地址，而不是随机分发16 *个*地址。假设我们将C类网络号从192.4.16分配到192.4.31。观察到此范围内所有地址的前20位是相同的（`11000000 00000100 0001`）。因此，我们有效创建的是一个20位的网络号 - 根据它可以支持的主机数量，它在B类网络号和C类号之间。换句话说，我们获得了以小于B类网络的块分配地址的高地址效率，以及可以在转发表中使用的单个网络前缀。观察到，为了使该方案起作用，我们需要分发共享公共前缀的C类地址块，这意味着每个块必须包含许多C类网络，其功率为2。

CIDR需要一种新的表示法来表示网络号或 *前缀*，因为前缀可以是任意长度。惯例是`/X`在前缀后面放置一个前缀，其中`X`前缀长度以位为单位。因此，对于上面的示例，所有网络192.4.16到192.4.31的20位前缀表示为192.4.16 / 20。相比之下，如果我们想要表示一个24位长的单个C类网络号，我们将其写为192.4.16 / 24。今天，由于CIDR是常态，听到人们谈论“削减24”前缀比C级网络更常见。请注意，以这种方式表示网络地址与`(mask, value)` 子网划分中使用的方法类似，只要`masks` 由最高位（从实际上几乎总是如此）开始的连续位组成。

![img](https://book.systemsapproach.org/internetworking/figures/f03-22-9780123850591.png)使用CIDR进行路由聚合。

我们刚刚看到的在网络边缘聚合路由的能力只是第一步。想象一下互联网服务提供商网络，其主要工作是为大量公司和校园（客户）提供互联网连接。如果我们为客户分配前缀，使得连接到提供商网络的许多不同客户网络共享一个共同的，更短的地址前缀，那么我们可以获得更多的路由聚合。考虑[图9中](https://book.systemsapproach.org/internetworking/basic-ip.html#cidreg)的示例。假设由提供商网络服务的八个客户每个都被分配了相邻的24位网络前缀。这些前缀都以相同的21位开头。由于所有客户都可以通过相同的提供商网络到达，因此它可以通过宣传他们共享的公共21位前缀来向所有客户通告单一路由。它可以做到这一点，即使不是所有的24位前缀已发放，只要供应商最终*会*有权将这些前缀分发给客户。实现此目的的一种方法是预先将一部分地址空间分配给提供者，然后让网络提供者根据需要将该空间的地址分配给其客户。请注意，与此简单示例相比，不需要所有客户前缀都具有相同的长度。

### 重新访问IP转发

In all our discussion of IP forwarding so far, we have assumed that we could find the network number in a packet and then look up that number in a forwarding table. However, now that we have introduced CIDR, we need to reexamine this assumption. CIDR means that prefixes may be of any length, from 2 to 32 bits. Furthermore, it is sometimes possible to have prefixes in the forwarding table that "overlap," in the sense that some addresses may match more than one prefix. For example, we might find both 171.69 (a 16-bit prefix) and 171.69.10 (a 24-bit prefix) in the forwarding table of a single router. In this case, a packet destined to, say, 171.69.10.5 clearly matches both prefixes. The rule in this case is based on the principle of "longest match"; that is, the packet matches the longest prefix, which would be 171.69.10 in this example. On the other hand, a packet destined to 171.69.20.5 would match 171.69 and *不是* 171.69.10，并且在路由表中没有任何其他匹配条目的情况下，171.69将是最长的匹配。

多年来，在转发表中有效地找到IP地址和可变长度前缀之间的最长匹配的任务是一个富有成效的研究领域。最着名的算法使用称为*PATRICIA树的方法*，该方法实际上是在CIDR之前很好地开发的。

## 地址转换（ARP）

在上一节中，我们讨论了如何将IP数据报传送到正确的物理网络，但忽略了如何将数据报送到该网络上的特定主机或路由器的问题。主要问题是IP数据报包含IP地址，但您要向其发送数据报的主机或路由器上的物理接口硬件仅了解该特定网络的寻址方案。因此，我们需要将IP地址转换为在该网络上有意义的链路级地址（例如，48位以太网地址）。然后，我们可以将IP数据报封装在包含该链路级地址的帧内，并将其发送到最终目的地或承诺将数据报转发到最终目的地的路由器。

将IP地址映射到物理网络地址的一种简单方法是在其IP地址的主机部分中编码主机的物理地址。例如，具有物理地址的主机`00100001 01001001`（在高位字节中具有十进制值33，在低位字节中具有81）可以被赋予IP地址`128.96.33.81`。虽然这种解决方案已在某些网络上使用，但其局限性在于此网络的物理地址长度不超过16位; 它们在C类网络上只能是8位长。这显然不适用于48位以太网地址。

更通用的解决方案是每个主机维护一个地址对表; 也就是说，该表将IP地址映射到物理地址。虽然此表可以由系统管理员集中管理，然后复制到网络上的每个主机，但更好的方法是让每个主机使用网络动态学习表的内容。这可以使用地址解析协议（ARP）来完成。ARP的目标是使网络上的每个主机能够建立IP地址和链路级地址之间的映射表。由于这些映射可能随时间而改变（例如，因为主机中的以太网卡断开并被具有新地址的新的以太网卡替换），所以条目定期超时并被移除。这种情况每15分钟发生一次。

ARP利用了许多链路级网络技术（如以太网）支持广播的优势。如果主机想要将IP数据报发送到它知道在同一网络上的主机（或路由器）（即，发送和接收节点具有相同的IP网络号），它首先检查缓存中的映射。如果未找到映射，则需要通过网络调用地址解析协议。它通过在网络上广播ARP查询来实现。此查询包含有问题的IP地址（目标IP地址）。每个主机都接收查询并检查它是否与其IP地址匹配。如果匹配，则主机将包含其链路层地址的响应消息发送回查询的发起者。发起者将此响应中包含的信息添加到其ARP表中。

查询消息还包括发送主机的IP地址和链路层地址。因此，当主机广播查询消息时，网络上的每个主机都可以了解发送方的链路级和IP地址，并将该信息放在其ARP表中。但是，并非每个主机都将此信息添加到其ARP表中。如果主机在其表中已经有该主机的条目，它将“刷新”该条目; 也就是说，它会重置丢弃条目之前的时间长度。如果该主机是查询的目标，则它会将有关发件人的信息添加到其表中，即使它没有该主机的条目也是如此。这是因为源主机很可能会向其发送应用程序级消息，并且它最终可能必须向源发送响应或ACK; 它需要来源' 这样做的物理地址。如果主机不是目标，并且在其ARP表中没有源的条目，则它不会为源添加条目。这是因为没有理由相信这个主机需要源的链路级地址; 没有必要使用这些信息来混淆其ARP表。

![img](https://book.systemsapproach.org/internetworking/figures/f03-23-9780123850591.png)用于将IP地址映射到以太网地址的ARP数据包格式。

[图10](https://book.systemsapproach.org/internetworking/basic-ip.html#arp)显示了IP到以太网地址映射的ARP数据包格式。事实上，ARP可用于许多其他类型的映射 - 主要区别在于地址大小。除了发送方和目标的IP和链路层地址之外，数据包还包含

- 一个`HardwareType`字段，指定物理网络的类型（例如，以太网）
- 一个`ProtocolType`字段，指定更高层协议（例如，IP）
- `HLen`（“硬件”地址长度）和`PLen`（“协议”地址长度）字段，分别指定链路层地址和更高层协议地址的长度
- 一个`Operation`字段，指定这是请求还是响应
- 源和目标硬件（以太网）和协议（IP）地址

请注意，ARP过程的结果可以作为[表1](https://book.systemsapproach.org/internetworking/basic-ip.html#ipfwdtab)中的转发表中的额外列添加。因此，例如，当R2需要将分组转发到网络2时，它不仅发现下一跳是R1，而且还找到要放在分组上的MAC地址以将其发送到R1。



重点外卖



我们现在已经看到了IP为处理异质性和规模而提供的基本机制。在异构性问题上，IP首先定义尽力服务模型，该模型对底层网络做出最小的假设; 最值得注意的是，此服务模型基于不可靠的数据报。IP然后对这个起点做了两个重要的补充：（1）通用数据包格式（碎片/重组是使这种格式在具有不同MTU的网络上工作的机制）和（2）用于识别所有主机的全局地址空间（ARP）是使这个全局地址空间在具有不同物理寻址方案的网络上工作的机制。在规模问题上，IP使用分层聚合来减少转发数据包所需的信息量。特别，

## 主机配置（DHCP）

制造商将以太网地址配置到网络适配器中，并且以确保这些地址全局唯一的方式管理此过程。这显然是确保连接到单个以太网（包括扩展LAN）的任何主机集合将具有唯一地址的充分条件。此外，我们要求以太网地址的唯一性。

相比之下，IP地址不仅必须在给定的互联网络上是唯一的，而且还必须反映互联网络的结构。如上所述，它们包含网络部分和主机部分，并且网络部分对于同一网络上的所有主机必须相同。因此，IP地址在制造时不可能一次配置到主机中，因为这意味着制造商知道哪些主机最终会在哪个网络上结束，这意味着主机一次，连接到一个网络，永远不会移动到另一个网络。因此，IP地址需要可重新配置。

除了IP地址之外，主机在开始发送数据包之前还需要有一些其他信息。其中最值得注意的是默认路由器的地址 - 它可以发送目的地址与发送主机不在同一网络上的数据包的位置。

大多数主机操作系统为系统管理员甚至用户提供了一种手动配置主机所需IP信息的方法; 但是，这种手动配置存在一些明显的缺点。一个是直接配置大型网络中的所有主机只需要做很多工作，尤其是当您认为在配置这些主机之前无法通过网络访问这些主机时。更重要的是，配置过程非常容易出错，因为必须确保每个主机都获得正确的网络号，并且没有两个主机接收相同的IP地址。出于这些原因，需要自动配置方法。主要方法使用称为*动态主机配置协议*（DHCP）的*协议*。

DHCP依赖于DHCP服务器的存在，该服务器负责向主机提供配置信息。管理域至少有一个DHCP服务器。在最简单的级别，DHCP服务器可以作为主机配置信息的集中存储库。例如，考虑在大公司的互联网络中管理地址的问题。DHCP使网络管理员不必走动到公司中的每个主机，手头都有地址列表和网络映射，并手动配置每个主机。相反，每个主机的配置信息可以存储在DHCP服务器中，并在引导或连接到网络时由每个主机自动检索。但是，管理员仍然会选择每个主机要接收的地址; 他只会将其存储在服务器中。在该模型中，每个主机的配置信息存储在一个表中，该表由某种形式的唯一客户机标识符索引，通常是硬件地址（例如，其网络适配器的以太网地址）。

更复杂的DHCP使用使网络管理员甚至无需为各个主机分配地址。在此模型中，DHCP服务器维护一个可用地址池，按需将其分发给主机。这大大减少了管理员必须执行的配置量，因为现在只需要为每个网络分配一系列IP地址（所有具有相同网络号）。

由于DHCP的目标是最小化主机运行所需的手动配置量，因此如果必须使用DHCP服务器的地址配置每个主机，则宁可失败。因此，DHCP面临的第一个问题是服务器发现问题。

要联系DHCP服务器，新引导或连接的主机会将 `DHCPDISCOVER`消息发送到作为IP广播地址的特殊IP地址（255.255.255.255）。这意味着它将被该网络上的所有主机和路由器接收。（路由器不会将此类数据包转发到其他网络，从而阻止向整个Internet广播。）在最简单的情况下，其中一个节点是网络的DHCP服务器。然后，服务器将回复生成发现消息的主机（所有其他节点将忽略它）。但是，并不是真的希望在每个网络上都需要一个DHCP服务器，因为这仍然会创建需要正确且一致地配置的潜在大量服务器。因此，DHCP使用*中继代理*的概念。每个网络上至少有一个中继代理，它只配置了一条信息：DHCP服务器的IP地址。当中继代理收到`DHCPDISCOVER`消息时，它会将其单播到DHCP服务器并等待响应，然后它将发送回请求客户端。将消息从主机中继到远程DHCP服务器的过程如图[11](https://book.systemsapproach.org/internetworking/basic-ip.html#dhcp-relay)所示。

![img](https://book.systemsapproach.org/internetworking/figures/f03-24-9780123850591.png)DHCP中继代理从主机接收广播DHCPDISCOVER消息，并向DHCP服务器发送单播DHCPDISCOVER。

下面的[图12](https://book.systemsapproach.org/internetworking/basic-ip.html#dhcp)显示了DHCP消息的格式。该消息实际上是使用在IP上运行的称为*用户数据报协议*（UDP）的协议发送的。UDP将在下一章中详细讨论，但它在此上下文中唯一有趣的事情是提供一个解复用密钥，该密钥表示“这是一个DHCP数据包”。

![img](https://book.systemsapproach.org/internetworking/figures/f03-25-9780123850591.png)DHCP数据包格式。

DHCP源自早期的称为BOOTP的协议，因此一些分组字段与主机配置不严格相关。在尝试获取配置信息时，客户端将其硬件地址（例如，其以太网地址）放在该`chaddr`字段中。DHCP服务器通过填写`yiaddr`（“您的”IP地址）字段并将其发送到客户端来进行回复。其他信息（例如此客户端使用的默认路由器）可以包含在该`options`字段中。

在DHCP动态地为主机分配IP地址的情况下，很明显主机无法无限期地保留地址，因为这最终会导致服务器耗尽其地址池。同时，主机不能依赖于回送其地址，因为它可能已经崩溃，已从网络中拔出或被关闭。因此，DHCP允许地址租用一段时间。一旦租约到期，服务器就可以自由地将该地址返回到其池中。具有租用地址的主机显然需要定期续订租约，实际上它仍然连接到网络并正常运行。



重点外卖



DHCP说明了扩展的一个重要方面：网络管理的扩展。虽然关于扩展的讨论通常侧重于保持网络设备中的状态不会过快增长，但重要的是要关注网络管理复杂性的增长。通过允许网络管理员为每个网络配置一系列IP地址而不是每个主机一个IP地址，DHCP可以提高网络的可管理性。

请注意，DHCP也可能会给网络管理带来更多复杂性，因为它使物理主机和IP地址之间的绑定更加动态。例如，如果有必要找到故障主机，这可能使网络管理员的工作更加困难。

## 错误报告（ICMP）

下一个问题是互联网如何处理错误。虽然IP非常愿意在变得艰难时丢弃数据报 - 例如，当路由器不知道如何转发数据报时，或者当数据报的一个片段无法到达目的地时 - 它不一定会无声地失败。IP始终配置有协同协议，称为*Internet控制消息协议*（ICMP），它定义了一旦路由器或主机无法成功处理IP数据报，就会发送回源主机的错误消息集合。例如，ICMP定义了错误消息，指示目标主机无法访问（可能是由于链路故障），重组过程失败，TTL已达到0，IP头校验和失败，等等。

ICMP还定义了一些路由器可以发送回源主机的控制消息。其中一个最有用的控制消息称为*ICMP-Redirect*，它告诉源主机有更好的路由到目的地。ICMP-Redirects用于以下情况。假设主机连接到连接了两个路由器的网络，称为*R1*和*R2*，主机使用R1作为其默认路由器。如果R1从主机接收数据报，根据其转发表，它知道R2对于特定目标地址是更好的选择，它会将ICMP-Redirect发送回主机，指示它使用R2进行所有发往该目的地的未来数据报。然后，主机将此新路由添加到其转发表中。

ICMP还提供了依据两种广泛使用的调试工具，`ping`和`traceroute`。`ping`使用ICMP回送消息来确定节点是否可访问和活动。`traceroute`使用一种稍微不直观的技术来确定沿目的地路径的路由器集合，这是本章末尾的一个练习的主题。

## 虚拟网络和隧道

我们通过考虑您可能没有预料到的问题来结束我们对知识产权的介绍，但这个问题变得越来越重要。到目前为止，我们的讨论集中在使不同网络上的节点能够以不受限制的方式相互通信。这通常是互联网的目标 - 每个人都希望能够向每个人发送电子邮件，并且新网站的创建者希望能够覆盖尽可能广泛的受众。但是，在许多情况下需要更多受控连接。这种情况的一个重要例子是*虚拟专用网络*（VPN）。

术语*VPN*严重过度使用且定义各不相同，但直观地说，我们可以通过首先考虑专用网络的概念来定义VPN。拥有许多站点的公司通常通过租用电话公司的传输线并使用这些线路互连站点来建立专用网络。在这样的网络中，通信仅限于在该公司的站点之间进行，出于安全原因这通常是期望的。使私有网络*虚拟化*，租用的传输线 - 不与任何其他公司共享 - 将被某种共享网络取代。虚拟电路（VC）是租用线路的非常合理的替代品，因为它仍然提供公司站点之间的逻辑点对点连接。例如，如果公司X有一个从站点A到站点B的VC，那么显然它可以在站点A和站点B之间发送数据包。但是，如果没有首先建立自己的虚拟站点，公司Y就无法将其数据包传送到站点B.电路到站点B，并且可以在管理上防止建立这样的VC，从而防止公司X和公司Y之间的不希望的连接。

[图13（a）](https://book.systemsapproach.org/internetworking/basic-ip.html#vpn)显示了两个独立公司的两个专用网络。在[图13（b）中，](https://book.systemsapproach.org/internetworking/basic-ip.html#vpn)它们都迁移到虚拟电路网络。保持真实专用网络的有限连接，但由于专用网络现在共享相同的传输设施和交换机，我们说已经创建了两个虚拟专用网络。

![img](https://book.systemsapproach.org/internetworking/figures/f03-26-9780123850591.png)虚拟专用网络的一个例子：（a）两个独立的专用网络; （b）两个共享公共交换机的虚拟专用网络。

在[图13中](https://book.systemsapproach.org/internetworking/basic-ip.html#vpn)，虚拟电路网络（例如，使用ATM）用于提供站点之间的受控连接。还可以使用IP网络提供类似的功能以提供连接。但是，我们不能将各个公司的网站连接到一个互联网络，因为这将提供公司X和公司Y之间的连接，我们希望避免这种连接。要解决这个问题，我们需要引入一个新的概念，即*IP隧道*。

我们可以将IP隧道视为一对节点之间的虚拟点对点链路，这对节点实际上由任意数量的网络隔开。虚拟链路在隧道入口处的路由器内创建，方法是为隧道远端的路由器提供IP地址。每当隧道入口处的路由器想要通过该虚拟链路发送分组时，它就将该分组封装在IP数据报内。IP报头中的目标地址是隧道远端路由器的地址，而源地址是封装路由器的地址。

![img](https://book.systemsapproach.org/internetworking/figures/f03-27-9780123850591.png)通过互联网的隧道。18.5.0.1是R2的地址，可以通过互联网从R1到达。

在隧道入口处的路由器的转发表中，该虚拟链路看起来很像普通链路。例如，考虑[图14中](https://book.systemsapproach.org/internetworking/basic-ip.html#tunnel)的网络。已从R1配置隧道到R2，并将虚拟接口编号指定为0.因此，R1中的转发表可能如 [表4所示](https://book.systemsapproach.org/internetworking/basic-ip.html#tunneltab)。



路由器R1的转发表。

| NetworkNum |   力宏    |
| :--------: | :-------: |
|     1      |   接口0   |
|     2      | 虚拟接口0 |
|    默认    |   界面1   |

R1有两个物理接口。接口0连接到网络1; 接口1连接到大型互联网络，因此是所有流量的默认值，这些流量与转发表中更具体的内容不匹配。此外，R1还有一个虚拟接口，它是隧道的接口。假设R1从网络1接收包含网络2中的地址的数据包。转发表说该数据包应该从虚拟接口0发出。为了从该接口发送数据包，路由器接收数据包，添加IP头发送到R2，然后继续转发数据包，就好像它刚收到一样。R2的地址是18.5.0.1; 由于该地址的网络号是18，而不是1或2，所以发往R2的数据包将从默认接口转发到互联网络中。

一旦数据包离开R1，它就会看到世界其他地方，就像发往R2的普通IP数据包一样，并相应转发。互联网络中的所有路由器都使用常规方式转发它，直到它到达R2。当R2收到数据包时，会发现它携带自己的地址，因此它会删除IP头并查看数据包的有效负载。它找到的是一个内部IP数据包，其目标地址在网络2中.R2现在处理此数据包，就像它接收的任何其他IP数据包一样。由于R2直接连接到网络2，因此它将数据包转发到该网络。[图14](https://book.systemsapproach.org/internetworking/basic-ip.html#tunnel)示出了当分组在网络上移动时分组的封装变化。

虽然R2充当隧道的端点，但没有什么可以阻止它执行路由器的正常功能。例如，它可能会收到一些未通过隧道传输的数据包，但这些数据包会发送到它知道如何到达的网络，并且会以正常方式转发它们。

您可能想知道为什么有人会想要在创建隧道并更改数据包封装时遇到的麻烦。一个原因是安全。通过加密，隧道可以成为跨公共网络的非常私密的链接。另一个原因可能是R1和R2具有一些在中间网络中不能广泛使用的能力，例如多播路由。通过将这些路由器与隧道连接，我们可以构建一个虚拟网络，其中具有此功能的所有路由器似乎都是直接连接的。构建隧道的第三个原因是通过IP网络从IP以外的协议传输数据包。只要隧道两端的路由器都知道如何处理这些其他协议，IP隧道将它们看作是一个点对点链路，通过它可以发送非IP数据包。隧道还提供了一种机制，通过该机制，我们可以强制将数据包传递到特定位置，即使其原始标头 - 被封装在隧道标头内的标头 - 可能表明它应该转到其他地方。因此，我们看到隧道是一种强大且非常通用的技术，用于在互联网络上构建虚拟链接。事实上，一般情况下，该技术是递归的，最常见的用例是隧道IP over IP。我们看到隧道是一种强大且非常通用的技术，用于在互联网络上构建虚拟链接。事实上，一般情况下，该技术是递归的，最常见的用例是隧道IP over IP。我们看到隧道是一种强大且非常通用的技术，用于在互联网络上构建虚拟链接。事实上，一般情况下，该技术是递归的，最常见的用例是隧道IP over IP。

隧道确实有它的缺点。一个是它增加了数据包的长度; 这可能代表短数据包带宽的重大浪费。较长的数据包可能会受到碎片化，这有其自身的一些缺点。隧道两端的路由器也可能存在性能影响，因为它们在添加和删除隧道头时需要做比正常转发更多的工作。最后，管理实体的管理成本负责设置隧道并确保它们由路由协议正确处理。

内容[什么是网络工作？](https://book.systemsapproach.org/internetworking/basic-ip.html#what-is-an-internetwork)[服务模式](https://book.systemsapproach.org/internetworking/basic-ip.html#service-model)[全球地址](https://book.systemsapproach.org/internetworking/basic-ip.html#global-addresses)[IP中的数据报转发](https://book.systemsapproach.org/internetworking/basic-ip.html#datagram-forwarding-in-ip)[子网和无类别寻址](https://book.systemsapproach.org/internetworking/basic-ip.html#subnetting-and-classless-addressing)[地址转换（ARP）](https://book.systemsapproach.org/internetworking/basic-ip.html#address-translation-arp)[主机配置（DHCP）](https://book.systemsapproach.org/internetworking/basic-ip.html#host-configuration-dhcp)[错误报告（ICMP）](https://book.systemsapproach.org/internetworking/basic-ip.html#error-reporting-icmp)[虚拟网络和隧道](https://book.systemsapproach.org/internetworking/basic-ip.html#virtual-networks-and-tunnels)





# 3.3路由

到目前为止，在本章中我们假设交换机和路由器对网络拓扑有足够的了解，因此可以选择应该输出每个数据包的正确端口。在虚拟电路的情况下，路由仅是连接请求分组的问题; 所有后续数据包都遵循与请求相同的路径。在数据报网络（包括IP网络）中，路由是每个数据包的问题。在任何一种情况下，交换机或路由器都需要能够查看目标地址，然后确定哪个输出端口是将数据包发送到该地址的最佳选择。正如我们在前面部分中看到的那样，交换机通过查询转发表来做出此决定。路由的基本问题是交换机和路由器如何在其转发表中获取信息。



重点外卖



我们重申了*转发*和*路由*之间经常被忽略的重要区别 。转发包括获取数据包，查看其目标地址，查询表，以及按该表确定的方向发送数据包。我们在前一节中看到了几个转发示例。路由是构建转发表的过程。我们还注意到转发是在节点本地执行的相对简单且定义明确的过程，而路由依赖于在整个网络历史中不断发展的复杂分布式算法。

而术语*转发表*和*路由表*有时可互换使用，我们将在这里区分它们。转发表是在转发数据包时使用的，因此必须包含足够的信息才能完成转发功能。这意味着转发表中的一行包含从网络前缀到出接口的映射以及一些MAC信息，例如下一跳的以太网地址。另一方面，路由表是由路由算法构建的表，作为构建转发表的前兆。它通常包含从网络前缀到下一跳的映射。它还可能包含有关如何学习此信息的信息，以便路由器能够决定何时应丢弃某些信息。

路由表和转发表是否实际上是单独的数据结构是一种实现选择，但有许多理由将它们分开。例如，转发表需要被构造为在转发分组时优化查找地址的过程，而路由表需要被优化以用于计算拓扑中的变化。在许多情况下，转发表甚至可以在专用硬件中实现，而这对于路由表来说很少。 [表格1](https://book.systemsapproach.org/internetworking/routing.html#rtab-ftab)下面提供了每种表格中一行的示例。在这种情况下，路由表告诉我们，IP地址为171.69.245.10的下一跳路由器将到达网络前缀18/8，而转发表包含有关如何将数据包转发到下一跳的确切信息：发送出接口号为0的MAC地址为8：0：2b：e4：b：1：2。请注意，最后一条信息由地址解析协议提供。



来自（a）路由和（b）转发表的示例行。

（一个）

| 前缀/长度 |    下一跳     |
| :-------: | :-----------: |
|   18/8    | 171.69.245.10 |

（b）中

| 前缀/长度 | 接口 |       MAC地址        |
| :-------: | :--: | :------------------: |
|   18/8    | IF0  | 8：0：2B：E4：B：1:2 |

在深入了解路由的细节之前，我们需要提醒自己，每当我们尝试构建Internet机制时，我们应该问的关键问题是：“这个解决方案是否会扩展？” 本节中描述的算法和协议的答案“不是那么多”。它们设计用于相当适中的网络 - 实际上可达几百个节点。但是，我们描述的解决方案确实可以作为当今Internet中使用的分层路由基础架构的构建块。具体而言，本节中描述的协议统称为*域内*路由协议或*内部网关协议*（IGP）。要理解这些术语，我们需要定义路由*域*。良好的工作定义是一种互联网络，其中所有路由器都在相同的管理控制下（例如，单个大学校园，或单个互联网服务提供商的网络）。当我们研究*域间*路由协议时，这个定义的相关性将在下一章中变得明显。目前，要记住的重要一点是，我们正在考虑在中小型网络环境中进行路由的问题，而不是考虑互联网规模的网络。

## 网络作为图表

路由本质上是图论的问题。 [图1](https://book.systemsapproach.org/internetworking/routing.html#graph-route)显示了代表网络的图表。标记为A到F的图的节点可以是主机，交换机，路由器或网络。对于我们的初步讨论，我们将关注节点是路由器的情况。图的边缘对应于网络链接。每个边缘都有一个相关的*成本*，这表明了通过该链路发送流量的可取性。关于边缘成本如何分配的讨论将在后面的部分中给出。

> 在本章中使用的示例网络（图形）中，我们使用无向边缘并为每个边缘分配单个成本。这实际上是一种轻微的简化。使边缘定向更准确，这通常意味着在每个节点之间将存在一对边缘 - 一个在每个方向上流动，并且每个边缘具有其自己的边缘成本。

![img](https://book.systemsapproach.org/internetworking/figures/f03-28-9780123850591.png)网络表示为图形。

路由的基本问题是找到任意两个节点之间的成本最低的路径，其中路径的成本等于构成路径的所有边的成本之和。对于像[图1中](https://book.systemsapproach.org/internetworking/routing.html#graph-route)那样的简单网络 ，您可以想象只计算所有最短路径并将它们加载到每个节点上的某个非易失性存储中。这种静态方法有几个缺点：

- 它不处理节点或链路故障。
- 它不考虑添加新节点或链接。
- 这意味着边缘成本不能改变，即使我们可能合理地希望链路成本随时间变化（例如，为高负载的链路分配高成本）。

由于这些原因，通过在节点之间运行路由协议，在大多数实际网络中实现路由。这些协议提供了一种分布式动态方法，可以解决在存在链路和节点故障以及改变边缘成本时找到成本最低的路径的问题。注意前一句中*分发*的词; 很难使集中式解决方案可扩展，因此所有广泛使用的路由协议都使用分布式算法。

路由算法的分布式特性是其成为如此丰富的研究和开发领域的主要原因之一 - 在使分布式算法运行良好方面存在许多挑战。例如，分布式算法提高了两个路由器在一个瞬间对到某个目的地的最短路径有不同想法的可能性。实际上，每个人都可能认为另一个人更接近目的地并决定将数据包发送到另一个目的地。显然，这样的数据包将被卡在一个循环中，直到两个路由器之间的差异得到解决，并且最好尽快解决它。这只是路由协议必须解决的问题类型的一个示例。

为了开始我们的分析，我们假设网络中的边缘成本是已知的。我们将研究两种主要的路由协议： *距离向量*和*链路状态*。在后面的部分中，我们将回到以有意义的方式计算边际成本的问题。

## 距离矢量（RIP）

距离矢量算法背后的想法由其名称提出。（此类算法的另一个常见名称是Bellman-Ford，仅次于其发明者。）每个节点构建一个包含所有其他节点的“距离”（成本）的一维数组（向量），并将该向量分配给其近邻。距离矢量路由的起始假设是每个节点知道到其每个直接连接的邻居的链路的成本。当路由器由网络管理器配置时，可以提供这些成本。向下的链接被分配无限成本。

![img](https://book.systemsapproach.org/internetworking/figures/f03-29-9780123850591.png)距离矢量路由：示例网络。



每个节点存储的初始距离（全局视图）。

|      |   一个   |    乙    |    C     |    d     |    Ë     |    F     |    G     |
| :--: | :------: | :------: | :------: | :------: | :------: | :------: | :------: |
| 一个 |    0     |    1     |    1     | \ infty∞ |    1     |    1     | \ infty∞ |
|  乙  |    1     |    0     |    1     | \ infty∞ | \ infty∞ | \ infty∞ | \ infty∞ |
|  C   |    1     |    1     |    0     |    1     | \ infty∞ | \ infty∞ | \ infty∞ |
|  d   | \ infty∞ | \ infty∞ |    1     |    0     | \ infty∞ | \ infty∞ |    1     |
|  Ë   |    1     | \ infty∞ | \ infty∞ | \ infty∞ |    0     | \ infty∞ | \ infty∞ |
|  F   |    1     | \ infty∞ | \ infty∞ | \ infty∞ | \ infty∞ |    0     |    1     |
|  G   | \ infty∞ | \ infty∞ | \ infty∞ |    1     | \ infty∞ |    1     |    0     |

要了解距离矢量路由算法的工作原理，最简单的方法是考虑[如图2](https://book.systemsapproach.org/internetworking/routing.html#dvroute)所示的示例。在此示例中，每个链接的成本设置为1，因此最低成本路径只是具有最少跳数的路径。（由于所有边都具有相同的成本，我们不会在图中显示成本。）我们可以像[表2](https://book.systemsapproach.org/internetworking/routing.html#dvtab1)一样表示每个节点关于到所有其他节点的距离的知识。请注意，每个节点只知道表中一行中的信息（左列中带有其名称的信息）。此处显示的全局视图在网络中的任何单个点都不可用。

我们可以将[表2](https://book.systemsapproach.org/internetworking/routing.html#dvtab1)中的每一行视为从一个节点到所有其他节点的距离列表，表示该节点的当前信念。最初，每个节点为其直接连接的邻居设置成本1\ infty∞到所有其他节点。因此，A最初认为它可以在一跳中到达B并且D不可达。存储在A处的路由表反映了这组信念，并包括A用于到达任何可达节点的下一跳的名称。最初，A的路由表如[表3所示](https://book.systemsapproach.org/internetworking/routing.html#dvtab2)。



节点A的初始路由表。

| 目的地 |   成本   | 力宏 |
| :----: | :------: | :--: |
|   乙   |    1     |  乙  |
|   C    |    1     |  C   |
|   d    | \ infty∞ |  -   |
|   Ë    |    1     |  Ë   |
|   F    |    1     |  F   |
|   G    | \ infty∞ |  -   |

距离矢量路由的下一步是每个节点向其直接连接的邻居发送包含其个人距离列表的消息。例如，节点F告诉节点A它可以以1的成本到达节点G; A也知道它可以以1的成本达到F，因此它增加了这些成本以通过F获得到达G的成本。这个总成本2小于无穷大的当前成本，所以A记录它可以通过F到达G的成本为2.同样，A从C学到D可以从C到达，成本为1; 它将这增加到达到C（1）的成本并且决定可以通过C以2的成本达到D，这比无穷大的旧成本更好。同时，A从C学到可以从C到达B的成本为1，因此得出结论：通过C到达B的成本是2。

此时，A可以更新其路由表，其中包含网络中所有节点的成本和下一跳。结果如[表4](https://book.systemsapproach.org/internetworking/routing.html#dvtab3)所示 。



节点A的最终路由表。

| 目的地 | 成本 | 力宏 |
| :----: | :--: | :--: |
|   乙   |  1   |  乙  |
|   C    |  1   |  C   |
|   d    |  2   |  C   |
|   Ë    |  1   |  Ë   |
|   F    |  1   |  F   |
|   G    |  2   |  F   |



每个节点存储的最终距离（全局视图）。

|      | 一个 |  乙  |  C   |  d   |  Ë   |  F   |  G   |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| 一个 |  0   |  1   |  1   |  2   |  1   |  1   |  2   |
|  乙  |  1   |  0   |  1   |  2   |  2   |  2   |  3   |
|  C   |  1   |  1   |  0   |  1   |  2   |  2   |  2   |
|  d   |  2   |  2   |  1   |  0   |  3   |  2   |  1   |
|  Ë   |  1   |  2   |  2   |  3   |  0   |  2   |  3   |
|  F   |  1   |  2   |  2   |  2   |  2   |  0   |  1   |
|  G   |  2   |  3   |  2   |  1   |  3   |  1   |  0   |

在没有任何拓扑更改的情况下，在每个节点具有完整的路由表之前，在邻居之间仅进行少量信息交换。获取一致路由信息到所有节点的过程称为*收敛*。 [表5](https://book.systemsapproach.org/internetworking/routing.html#dvtab4)显示了路由收敛时从每个节点到所有其他节点的最终成本集。我们必须强调网络中没有一个节点拥有该表中的所有信息 - 每个节点只知道自己的路由表的内容。像这样的分布式算法的优点在于它使所有节点能够在没有任何集中权限的情况下实现网络的一致视图。

在我们讨论距离矢量路由完成之前，有一些细节需要填写。首先，我们注意到有两种不同的情况，在这种情况下，给定节点决定向其邻居发送路由更新。其中一种情况是 *定期*更新。在这种情况下，即使没有任何更改，每个节点也会经常自动发送更新消息。这可以让其他节点知道该节点仍在运行。它还确保他们不断获取当前路线变得不可行时可能需要的信息。这些定期更新的频率因协议而异，但通常在几秒到几分钟的数量级。第二种机制，有时称为 *触发*每当节点注意到链路故障或从其邻居之一接收到导致其更改其路由表中的路由之一的更新时，就会发生更新。每当节点的路由表发生更改时，它会向其邻居发送更新，这可能会导致其表的更改，从而导致它们向其邻居发送更新。

现在考虑当链路或节点发生故障时会发生什么。首先注意到的节点向邻居发送新的距离列表，通常系统会很快稳定下来到新的状态。至于节点如何检测到故障的问题，有几个不同的答案。在一种方法中，节点通过发送控制分组并查看它是否接收到确认来连续地测试到另一节点的链路。在另一种方法中，如果节点没有接收到最后几个更新周期的预期周期性路由更新，则节点确定链路（或链路另一端的节点）是关闭的。

要了解节点检测到链路故障时会发生什么，请考虑当F检测到其到G的链路出现故障时会发生什么。首先，F将其到G的新距离设置为无穷大并将该信息传递给A.因为A知道它到G的2跳路径是通过F，A也会将其距离设置为G到无穷大。但是，随着C的下一次更新，A会得知C有一条到G的2跳路径。因此，A会知道它可以通过C在3跳中达到G，这小于无穷大，所以A会更新相应的表。当它将此通告给F时，节点F将知道它可以以4到A的成本到达G，这小于无穷大，并且系统将再次变得稳定。

不幸的是，略有不同的情况可能会阻止网络稳定。例如，假设从A到E的链路断开。在下一轮更新中，A将无穷远的距离通告给E，但是B和C通告2到E的距离。根据事件的确切时间，可能发生以下情况：节点B，听到E可以是从C开出2跳，得出结论是它可以在3跳中达到E并将其通告给A; 节点A得出结论，它可以在4跳中达到E并将其通告给C; 节点C断定它可以在5跳中达到E; 等等。只有当距离达到某个足以被视为无限的数字时，此循环才会停止。同时，没有节点实际知道E不可达，并且网络的路由表不稳定。 *数到无穷大的*问题。

这个问题有几个部分解决方案。第一个是使用一些相对较小的数字作为无穷大的近似值。例如，我们可能会确定跨越某个网络的最大跳数永远不会超过16，因此我们可以选择16作为表示无穷大的值。这至少限制了计数到无穷大所需的时间。当然，如果我们的网络增长到一些节点间隔超过16跳的程度，它也可能会出现问题。

一种改善稳定路由的时间的技术称为*水平分割*。这个想法是，当节点向其邻居发送路由更新时，它不会将从每个邻居学到的路由发送回该邻居。例如，如果B在其表中具有路由（E，2，A），则它知道它必须从A学习该路由，因此每当B向A发送路由更新时，它都不包括该路由（E ，2）在该更新中。在水平分割的更强变化中，称为*具有毒性逆转的*水平*分割*，B实际上将该路径发送回A，但是它在路径中放置负信息以确保A最终不会使用B到达E.例如，B发送路线（E，\ infty∞）到A.这两种技术的问题在于它们仅适用于涉及两个节点的路由循环。对于较大的路由环路，需要采取更激烈的措施。继续上面的例子，如果B和C在听到A之间的链路故障之前已经等了一段时间才向E发布路由，他们就会发现他们都没有真正有通往E的路由。不幸的是，这种方法延迟了收敛协议; 融合速度是其竞争对手链路状态路由的关键优势之一，后一部分的主题。

### 履行

实现此算法的代码非常简单; 我们在这里只提供一些基础知识。结构`Route`定义路由表中的每个条目，而常量`MAX_TTL`指定条目在丢弃之前保留在表中的时间长度。

```c
#define MAX_ROUTES      128     /* maximum size of routing table */
#define MAX_TTL         120     /* time (in seconds) until route expires */

typedef struct {
    NodeAddr  Destination;    /* address of destination */
    NodeAddr  NextHop;        /* address of next hop */
    int        Cost;          /* distance metric */
    u_short   TTL;            /* time to live */
} Route;

int      numRoutes = 0;
Route    routingTable[MAX_ROUTES];
```

基于新路由更新本地节点的路由表的例程由下式给出`mergeRoute`。虽然未示出，但是定时器功能定期扫描节点路由表中的路由列表，减少`TTL`每条路由的（生存时间）字段，并丢弃任何有时间为0的路由。但是，请注意，`TTL`当`MAX_TTL`来自相邻节点的更新消息重新确认路由时，字段被重置。

```c
void
mergeRoute (Route *new)
{
    int i;

    for (i = 0; i < numRoutes; ++i)
    {
        if (new->Destination == routingTable[i].Destination)
        {
            if (new->Cost + 1 < routingTable[i].Cost)
            {
                /* found a better route: */
                break;
            } else if (new->NextHop == routingTable[i].NextHop) {
                /* metric for current next-hop may have changed: */
                break;
            } else {
                /* route is uninteresting---just ignore it */
                return;
            }
        }
    }
    if (i == numRoutes)
    {
        /* this is a completely new route; is there room for it? */
        if (numRoutes < MAXROUTES)
        {
            ++numRoutes;
        } else {
            /* can`t fit this route in table so give up */
            return;
        }
    }
    routingTable[i] = *new;
    /* reset TTL */
    routingTable[i].TTL = MAX_TTL;
    /* account for hop to get to next node */
    ++routingTable[i].Cost;
}
```

最后，该过程`updateRoutingTable`是调用`mergeRoute`以合并从相邻节点接收的路由更新中包含的所有路由的主例程。

```c
void
updateRoutingTable (Route *newRoute, int numNewRoutes)
{
    int i;

    for (i=0; i < numNewRoutes; ++i)
    {
        mergeRoute(&newRoute[i]);
    }
}
```

### 路由信息协议（RIP）

IP网络中更广泛使用的路由协议之一是路由信息协议（RIP）。它在IP早期的广泛使用在很大程度上归功于它与Unix的流行的Berkeley Software Distribution（BSD）版本一起发布，从中衍生出许多商业版本的Unix。它也非常简单。RIP是基于刚刚描述的距离矢量算法构建的路由协议的规范示例。

互联网络中的路由协议与上述理想化的图模型略有不同。在互联网络中，路由器的目标是学习如何将数据包转发到各种*网络*。因此，路由器不是宣传到达其他路由器的成本，而是宣传到达网络的成本。例如，在 [图3中](https://book.systemsapproach.org/internetworking/routing.html#rip-eg)，路由器C将向路由器A通告它可以以0的成本到达网络2和3（它直接连接到网络），成本1的网络5和6以及网络4的网络4费用2。

![img](https://book.systemsapproach.org/internetworking/figures/f03-30-9780123850591.png)运行RIP的示例网络。

![img](https://book.systemsapproach.org/internetworking/figures/f03-31-9780123850591.png)RIPv2数据包格式。

我们可以在[图4](https://book.systemsapproach.org/internetworking/routing.html#rip)中的RIP（版本2）数据包格式中看到这种情况的证据 。大部分数据包都被`(address, mask, distance)`三元组占用 。但是，路由算法的原理是一样的。例如，如果路由器A从路由器B获知可以通过B以较低的成本到达网络X而不是通过路由表中的现有下一跳，则A相应地更新网络号的成本和下一跳信息。

RIP实际上是距离矢量路由的相当简单的实现。运行RIP的路由器每隔30秒发送一次广告; 每当来自另一个路由器的更新导致其更改其路由表时，路由器也会发送更新消息。一个兴趣点是它支持多个地址系列，而不仅仅是IP - 这是`Family`广告部分的原因。RIP版本2（RIPv2）还引入了前面部分中描述的子网掩码，而RIP版本1使用了旧的有类IP地址。

正如我们将在下面看到的，可以对路由协议中的链接使用一系列不同的度量或成本。RIP采用最简单的方法，所有链路成本都等于1，就像我们上面的例子一样。因此，它总是试图找到最小跳跃路线。有效距离为1到15，其中16表示无穷大。这也限制了RIP在相当小的网络上运行 - 那些没有超过15跳的路径。

## 链路状态（OSPF）

链路状态路由是域内路由协议的第二大类。链路状态路由的起始假设与距离矢量路由的起始假设非常相似。假设每个节点能够找到到其邻居的链路状态（向上或向下）以及每个链路的成本。同样，我们希望为每个节点提供足够的信息，使其能够找到任何目的地的最低成本路径。链路状态协议背后的基本思想非常简单：每个节点都知道如何到达其直接连接的邻居，如果我们确保将这些知识的全部信息传播到每个节点，那么每个节点都将具有足够的网络知识构建完整的网络地图。这显然是找到到网络中任何点的最短路径的充分条件（尽管不是必需的）。因此，链路状态路由协议依赖于两种机制：链路状态信息的可靠传播，以及从所有累积的链路状态知识的总和计算路由。

### 可靠的洪水

*可靠的泛洪*是确保参与路由协议的所有节点从所有其他节点获得链路状态信息的副本的过程。正如*泛滥*一词所暗示的那样，基本思想是节点在其所有直接连接的链路上发送其链路状态信息; 接收此信息的每个节点然后在*其*所有链接上转发它。此过程一直持续到信息到达网络中的所有节点。

更确切地说，每个节点创建一个更新数据包，也称为 *链路状态数据包*（LSP），其中包含以下信息：

- 创建LSP的节点的ID
- 该节点的直接连接邻居列表，以及每个节点的链接开销
- 序号
- 这个数据包的生存时间

启用路线计算需要前两项; 最后两个用于使数据包溢流到所有节点的过程可靠。可靠性包括确保您拥有最新的信息副本，因为来自一个节点的LSP可能存在多个相互矛盾的LSP。事实证明，使洪水可靠是非常困难的。（例如，ARPANET中使用的早期版本的链路状态路由导致该网络在1981年失败。）

洪水以下列方式运作。首先，使用确认和重传来使相邻路由器之间的LSP传输可靠，就像在可靠的链路层协议中一样。但是，为了可靠地将LSP泛洪到网络中的所有节点，还需要几个步骤。

考虑一个节点X，它接收源自某个其他节点Y的LSP的副本。注意，Y可以是与X相同的路由域中的任何其他路由器.X检查它是否已经存储了来自的LSP的副本是。如果不是，它存储LSP。如果它已经有副本，它会比较序列号; 如果新LSP具有更大的序列号，则假定它是更新的，并且存储LSP，替换旧的LSP。较小（或相等）的序列号意味着比存储的LSP更旧（或不更新），因此它将被丢弃，不需要进一步的操作。如果收到的LSP是较新的LSP，则X然后将该LSP的副本发送到其所有邻居，除了刚从其接收LSP的邻居。LSP没有被发送回接收它的节点的事实有助于结束LSP的泛洪。由于X将LSP传递给其所有邻居，然后他们转而做同样的事情，最新的LSP副本最终到达所有节点。

![img](https://book.systemsapproach.org/internetworking/figures/f03-32-9780123850591.png)链路状态包的泛洪：（a）LSP到达节点X; （b）X泛洪LSP到A和C; （c）A和C泛洪LSP到B（但不是X）; （d）洪水已完成。

[图5](https://book.systemsapproach.org/internetworking/routing.html#flood)显示了在小型网络中泛洪的LSP。每个节点在存储新LSP时都会变为阴影。在 [图5（a）中](https://book.systemsapproach.org/internetworking/routing.html#flood)的LSP到达节点X，其发送给邻居A和C在[图5（b）中](https://book.systemsapproach.org/internetworking/routing.html#flood)。A和C不会将其发送回X，而是将其发送到B.由于B收到两个相同的LSP副本，它将接受先到达的那个并忽略第二个作为重复。然后它将LSP传递给D，D没有邻居将其泛洪，并且过程完成。

就像在RIP中一样，每个节点在两种情况下生成LSP。周期性定时器的到期或拓扑的改变可以导致节点生成新的LSP。但是，节点生成LSP的唯一基于拓扑的原因是，如果其中一个直接连接的链路或直接邻居发生了故障。在某些情况下，链路层协议可以检测到链路故障。可以使用周期性“hello”分组来检测邻居的消亡或与该邻居的连接丢失。每个节点以定义的间隔将它们发送到其直接邻居。如果在没有从邻居收到“hello”的情况下经过足够长的时间，则将声明到该邻居的链接，并且将生成新的LSP以反映该事实。

链路状态协议的泛洪机制的一个重要设计目标是必须尽快将最新信息充斥到所有节点，而旧信息必须从网络中移除而不允许循环。此外，显然希望最小化在网络周围发送的路由流量的总量; 毕竟，从实际使用网络应用程序的人的角度来看，这只是开销。接下来的几段描述了实现这些目标的一些方法。

减少开销的一种简单方法是避免生成LSP，除非绝对必要。这可以通过使用很长的定时器来完成 - 通常是大约数小时 - 用于定期生成LSP。鉴于泛洪协议在拓扑发生变化时真正可靠，可以安全地假设不需要经常发送“无变化”的消息。

为了确保旧信息被更新的信息替换，LSP携带序列号。每次节点生成新的LSP时，它会将序列号递增1.与协议中使用的大多数序列号不同，这些序列号不会被包装，因此字段需要非常大（例如，64位）。如果一个节点出现故障然后重新启动，它将以序号0开始。如果节点长时间停机，该节点的所有旧LSP都将超时（如下所述）; 否则，该节点最终会收到一个具有更高序列号的自己的LSP副本，然后它可以递增并用作自己的序列号。这将确保其新LSP替换节点发生故障之前遗留的任何旧LSP。

LSP也有时间存在。这用于确保最终从网络中删除旧的链路状态信息。节点总是递减新接收的LSP的TTL，然后将其泛洪到其邻居。它还在LSP存储在节点中时“老化”。当TTL达到0时，节点以TTL为0重新激活LSP，该网络被网络中的所有节点解释为删除该LSP的信号。

### 路线计算

一旦给定节点具有来自每个其他节点的LSP的副本，它就能够计算网络拓扑的完整映射，并且从该映射能够确定到每个目的地的最佳路由。那么，问题就在于如何根据这些信息计算路线。该解决方案基于图论中众所周知的算法-Dijkstra的最短路径算法。

我们首先用图论方法定义Dijkstra算法。想象一个节点获取它收到的所有LSP并构造网络的图形表示，其中N表示图中的节点集，l（i，j）表示与之间的边缘相关的非负成本（权重）。节点i，j在N和l（i，j）=\ infty 如果没有边连接i和j，则为∞。在下面的描述中，我们让s in N表示该节点，即执行算法的节点，以找到N中所有其他节点的最短路径。此外，该算法保持以下两个变量：M表示该组的到目前为止由算法合并的节点，并且C（n）表示从s到每个节点n的路径的成本。鉴于这些定义，算法定义如下：

```pseudo
M = {s}
for each n in N - {s}
    C(n) = l(s,n)
while (N != M)
    M = M + {w} such that C(w) is the minimum for all w in (N-M)
    for each n in (N-M)
    C(n) = MIN(C(n), C(w)+l(w,n))
```

基本上，该算法的工作原理如下。我们从包含此节点的M开始，然后`C(n)`使用直接连接节点的已知成本将成本表（阵列）初始化到其他节点。然后，我们寻找以最低成本（w）可达的节点并将其添加到M.最后，我们通过考虑通过w到达节点的成本来更新成本表。在算法的最后一行，如果从源到w然后跟随从w到n的链接的总成本小于我们必须的旧路由，我们选择到节点n的新路由通过节点w ñ。重复此过程，直到所有节点都合并到M.

在实践中，每个交换机使用称为*前向搜索*算法的Dijkstra算法的实现直接从它收集的LSP计算其路由表。具体来说，每个交换机都有两个列表，称为`Tentative`和`Confirmed`。这些列表中的每一个都包含一组表单条目`(Destination, Cost, NextHop)`。算法的工作原理如下：

1. 使用`Confirmed`自己的条目初始化列表; 此条目的成本为0。
2. 对于刚刚添加到`Confirmed`上一步列表中的节点`Next`，将其称为节点并选择其LSP。
3. 对于每一个邻居（`Neighbor`中）`Next`，计算成本（`Cost`），以达到该`Neighbor`作为成本从自己的总和`Next`，并从`Next`到`Neighbor`。
   1. 如果`Neighbor`当前既不在列表中`Confirmed`也不在 `Tentative`列表中，那么添加`(Neighbor, Cost, NextHop)`到 `Tentative`列表中，`NextHop`我要去的方向在哪里`Next`。
   2. 如果`Neighbor`是目前的`Tentative`列表，而 `Cost`少于当前列出的费用`Neighbor`，然后更换当前条目有`(Neighbor, Cost, NextHop)`，这里`NextHop`是我去到达方向`Next`。
4. 如果`Tentative`列表为空，请停止。否则，从`Tentative`列表中选择成本最低的条目，将其移至 `Confirmed`列表，然后返回步骤2。

![img](https://book.systemsapproach.org/internetworking/figures/f03-33-9780123850591.png)链路状态路由：示例网络。

当我们看一个例子时，这将变得更容易理解。考虑[图6](https://book.systemsapproach.org/internetworking/routing.html#lsroute)中描绘的网络。请注意，与我们之前的示例不同，此网络具有一系列不同的边缘成本。[表6描述](https://book.systemsapproach.org/internetworking/routing.html#ls_trace)了为节点D构建路由表的步骤。我们通过使用它们所连接的节点的名称来表示D的两个输出，B和C.注意算法似乎在假引线上的方式（就像B的11单位成本路径一样，这是第一个添加到`Tentative`列表中的成本路径），但最终成为所有节点的最低成本路径。



构建节点D的路由表的步骤

|  步  |                      确认                       |          试验           | 评论                                                         |
| :--: | :---------------------------------------------: | :---------------------: | :----------------------------------------------------------- |
|  1   |                  （d，0， - ）                  |                         | 由于D是确认列表中唯一的新成员，请查看其LSP。                 |
|  2   |                  （d，0， - ）                  | （B，11，B）（C，2，C） | D's LSP表示我们可以通过成本11到达B到B，这比任何一个列表上的任何其他内容都要好，所以把它放在`Tentative`列表中; 同样的C. |
|  3   |            （D，0， - ）（C，2，C）             |      （B，11，B）       | 将`Tentative`（C）的最低成本成员列入`Confirmed`清单。接下来，检查新确认的成员（C）的LSP。 |
|  4   |            （D，0， - ）（C，2，C）             | （B，5，C）（A，12，C） | 达到B到C的成本是5，所以替换（B，11，B）。C的LSP告诉我们，我们可以以12的成本达到A. |
|  五  |       （D，0， - ）（C，2，C）（B，5，C）       |      （A，12，C）       | 移动`Tentative`（B）的最低成本成员`Confirmed`，然后查看其LSP。 |
|  6   |       （D，0， - ）（C，2，C）（B，5，C）       |      （A，10，C）       | 由于我们可以在成本5到B达到A，因此请更换`Tentative`条目。     |
|  7   | （D，0， - ）（C，2，C）（B，5，C）（A，10，C） |                         | 移动`Tentative`（A）的最低成本成员`Confirmed`，我们都完成了。 |

链路状态路由算法具有许多不错的属性：它已被证明可以快速稳定，不会产生大量流量，并且可以快速响应拓扑更改或节点故障。在缺点方面，存储在每个节点的信息量（网络中每个其他节点一个LSP）可能非常大。这是路由的基本问题之一，并且是更一般的可伸缩性问题的实例。针对特定问题（每个节点可能需要的存储量）和一般问题（可伸缩性）的一些解决方案将在下一节中讨论。



重点外卖



距离矢量和链路状态算法之间的差异可以总结如下。在距离向量中，每个节点仅与其直接连接的邻居进行通信，但它告诉它们所学习的所有内容（即到所有节点的距离）。在链路状态中，每个节点与所有其他节点进行通信，但它只告诉它们确切知道的内容（即，只有其直接连接的链路的状态）。

### 开放最短路径优先协议（OSPF）

最广泛使用的链路状态路由协议之一是OSPF。第一个词“开放”指的是它是一个开放的非专有标准，是在互联网工程任务组（IETF）的支持下创建的。“SPF”部分来自链路状态路由的替代名称。OSPF为上述基本链路状态算法添加了许多功能，包括：

- *路由消息的认证* - 分布式路由算法的一个特征是它们将信息从一个节点分散到许多其他节点，因此整个网络可能受到来自一个节点的不良信息的影响。因此，确保参与协议的所有节点都可以信任是一个好主意。验证路由消息有助于实现此目的。早期版本的OSPF使用简单的8字节密码进行身份验证。这不是一种足够强大的身份验证形式，可以防止专门的恶意用户，但它可以缓解由于配置错误或偶然攻击造成的一些问题。（在版本2中，RIP添加了类似的身份验证形式。）后来添加了强加密身份验证。
- *附加层次结构 - 层次结构*是用于使系统更具可扩展性的基本工具之一。OSPF通过允许将域划分为*区域*，将另一层层次结构引入路由 。这意味着域中的路由器不一定需要知道如何到达该域内的每个网络 - 它可以通过仅知道如何到达正确的区域来获得。因此，必须传输并存储在每个节点中的信息量减少。
- *负载均衡* -OSPF允许为同一地点分配多条路由相同的成本，并使流量均匀分布在这些路由上，从而更好地利用可用的网络容量。

![img](https://book.systemsapproach.org/internetworking/figures/f03-34-9780123850591.png)OSPF报头格式。

有几种不同类型的OSPF消息，但都以相同的头开头，[如图7](https://book.systemsapproach.org/internetworking/routing.html#ospf)所示。该`Version`字段当前设置为2，`Type`字段可以取值1到5. `SourceAddr`标识消息的发送方，并且`AreaId`是节点所在区域的32位标识符。除认证数据外，整个数据包使用与IP报头相同的算法由16位校验和保护。`Authentication type`如果不使用身份验证， 则为0; 否则，它可能是1，表示使用简单密码，或2，表示使用加密验证校验和。在后一种情况下，该`Authentication`字段携带密码或加密校验和。

在五种OSPF消息类型中，类型1是“hello”消息，路由器发送给它的对等体以通知它它仍然存活并如上所述连接。其余类型用于请求，发送和确认链接状态消息的接收。OSPF中链路状态消息的基本构建块是链路状态通告（LSA）。一条消息可能包含许多LSA。我们在这里提供LSA的一些细节。

与任何互联网络路由协议一样，OSPF必须提供有关如何到达网络的信息。因此，OSPF必须提供比上述简单的基于图形的协议更多的信息。具体而言，运行OSPF的路由器可以生成链路状态数据包，该数据包通告直接连接到该路由器的一个或多个网络。此外，通过某个链路连接到另一个路由器的路由器必须通过链路通告到达该路由器的成本。这两种类型的广告对于使域中的所有路由器能够确定到达该域中的所有网络的成本以及每个网络的适当下一跳是必要的。

![img](https://book.systemsapproach.org/internetworking/figures/f03-35-9780123850591.png)OSPF链路状态通告。

[图8](https://book.systemsapproach.org/internetworking/routing.html#ospf-lsa)显示了类型1链路状态通告的数据包格式。类型1 LSA通告路由器之间的链路成本。类型2 LSA用于通告广告路由器所连接的网络，而其他类型用于支持附加层次结构，如下一节所述。LSA中的许多领域应该从前面的讨论中熟悉。这`LS Age`相当于一个生存时间，除了它计时，LSA在年龄达到规定的最大值时到期。该`Type`字段告诉我们这是1型LSA。

在类型1 LSA中，字段`Link state ID`和`Advertising router`字段是相同的。每个都为创建此LSA的路由器携带32位标识符。虽然可以使用许多分配策略来分配此ID，但在路由域中它必须是唯一的并且给定路由器始终使用相同的路由器ID。选择满足这些要求的路由器ID的一种方法是从分配给该路由器的所有IP地址中选择最低的IP地址。（回想一下，路由器的每个接口上可能有不同的IP地址。）

在`LS sequence number`如上述那样检测到旧的或重复的LSA被精确地使用。这`LS checksum`与我们在其他协议中看到的其他类似; 当然，它用于验证数据是否已损坏。它涵盖了数据包中的所有字段`LS Age`，因此每次`LS Age`递增时都不需要重新计算校验和。`Length`是完整LSA的长度（以字节为单位）。

现在我们来看看实际的链接状态信息。由于存在TOS（服务类型）信息，这有点复杂。暂时忽略这一点，LSA中的每个链接都由a `Link ID`，some `Link Data`和a表示`metric`。这两个字段中的前两个标识了链接; 一种常见的方法是使用链路远端的路由器的路由器ID作为`Link ID`，然后`Link Data`在必要时使用消除多个并行链路之间的歧义。这`metric`当然是链接的成本。`Type` 告诉我们关于链接的一些信息 - 例如，如果它是一个点对点链接。

存在TOS信息以允许OSPF基于其TOS字段中的值为IP分组选择不同的路由。不是将单个度量指定给链接，而是可以根据数据的TOS值分配不同的度量。例如，如果我们的网络中有一个非常适合延迟敏感流量的链接，我们可以为表示低延迟的TOS值和其他所有内容的高度量值指定一个低指标。然后，OSPF将为那些将其TOS字段设置为该值的数据包选择不同的最短路径。值得注意的是，在撰写本文时，此功能尚未得到广泛部署。

## 度量

前面的讨论假设在执行路由算法时已知链路成本或度量。在本节中，我们将研究一些计算链接成本的方法，这些方法已在实践中证明是有效的。我们已经看到的一个非常合理且非常简单的例子是为所有链路分配成本1 - 最低成本路由将是具有最少跳数的路由。然而，这种方法有几个缺点。首先，它不会在延迟的基础上区分链接。因此，具有250毫秒延迟的卫星链路看起来与具有1毫秒延迟的地面链路一样对路由协议具有吸引力。其次，它不区分容量上的路由，使1-Mbps链路看起来与10-Gbps链路一样好。最后，它没有根据当前负载区分链接，使得无法绕过重载的链接。事实证明，最后一个问题是最困难的，因为您试图在单个标量成本中捕获链接的复杂和动态特征。

ARPANET是许多不同的链路成本计算方法的试验场。（这也是链路状态在距离矢量路由上的优越稳定性被证明的地方;原始机制使用距离矢量，而后一版本使用链路状态。）以下讨论追踪ARPANET路由度量的演变，并且，这样做，探讨了问题的微妙方面。

原始ARPANET路由度量测量了在每个链路上等待传输的队列的数量，这意味着具有排队等待传输的10个分组的链路被分配比具有排队等待传输的5个分组的链路更大的成本权重。然而，使用队列长度作为路由度量并不能很好地工作，因为队列长度是负载的人为测量 - 它将数据包移向最短的队列而不是目的地，这种情况对于我们这些从线路跳出来的人来说太熟悉了去杂货店排队。更准确地说，原始ARPANET路由机制受到以下事实的影响：它没有考虑链路的带宽或延迟。

ARPANET路由算法的第二个版本考虑了链路带宽和延迟，并使用延迟而不仅仅是队列长度作为负载的度量。这样做如下。首先，每个传入的数据包都带有时间戳，其到达路由器的时间（`ArrivalTime`）; 它也离开了路由器（`DepartTime`）的出发时间。其次，当从另一侧接收到链路级ACK时，该节点计算该分组的延迟为

```c
Delay = (DepartTime - ArrivalTime) + TransmissionTime + Latency
```

其中`TransmissionTime`和`Latency`为链路静态定义并分别捕获链路的带宽和延迟。请注意，在这种情况下，`DepartTime - ArrivalTime`表示由于加载而导致数据包在节点中延迟（排队）的时间。如果ACK没有到达，而是数据包超时，则`DepartTime`重置为*重传*数据包的时间。在这种情况下， `DepartTime - ArrivalTime`捕获链路的可靠性 - 数据包重传越频繁，链路可靠性越低，我们越想避免它。最后，分配给每个链路的权重来自最近通过该链路发送的分组所经历的平均延迟。

虽然比原始机制有所改进，但这种方法也存在很多问题。在轻负载下，它工作得相当好，因为延迟的两个静态因素主导了成本。然而，在重负载下，拥挤的链路将开始宣传非常高的成本。这导致所有流量从该链路移开，使其闲置，因此它将宣传低成本，从而吸引所有流量，等等。这种不稳定性的影响是，在负载很重的情况下，许多链路实际上会花费大量时间闲置，这是您在重负载下最不想要的。

另一个问题是链接值的范围太大。例如，负载较重的9.6-kbps链路的成本可能比轻载的56-kbps链路高出127倍。（请记住，我们大约在1975年谈论ARPANET。）这意味着路由算法将选择一条路径，其中包含126跳轻载56 kbps链路，优先于1跳9.6 kbps路径。虽然从过载的线路中减少一些流量是一个好主意，但它看起来没有吸引力，以至于它失去了所有的流量。一跳一次使用126跳通常是对网络资源的错误使用。此外，卫星链路受到了不应有的惩罚，因此空闲的56kbps卫星链路看起来比空闲的9.6kbps地面链路要昂贵得多，即使前者可以为高带宽应用提供更好的性能。

第三种方法解决了这些问题。主要变化是大幅度压缩度量的动态范围，考虑链接类型，并平滑度量随时间的变化。

通过几种机制实现平滑。首先，将延迟测量转换为链路利用率，并将该数量与上次报告的利用率进行平均，以抑制突然变化。其次，对于度量标准从一个测量周期到下一个测量周期的变化程度存在严格的限制。通过平滑成本的变化，所有节点一次放弃路线的可能性大大降低。

通过将测量的利用率，链路类型和链路速度馈送到[图9](https://book.systemsapproach.org/internetworking/routing.html#metric)中以图形方式示出的功能来实现动态范围的压缩。下面。请注意以下事项：

![img](https://book.systemsapproach.org/internetworking/figures/f03-36-9780123850591.png)修订了ARPANET路由度量与链路利用率。

- 高负载链路在空闲时的成本永远不会超过其成本的三倍。
- 最昂贵的链接只是最便宜的成本的七倍。
- 高速卫星链路比低速地面链路更具吸引力。
- 成本是仅在中等到高负载下链路利用率的函数。

所有这些因素都意味着链接不太可能被普遍抛弃，因为成本增加三倍可能会使某些路径的链接缺乏吸引力，同时让它仍然是其他路径的最佳选择。[图9](https://book.systemsapproach.org/internetworking/routing.html#metric)中的曲线的斜率，偏移和断点是通过大量的试验和错误得出的，并且它们经过仔细调整以提供良好的性能。

尽管进行了所有这些改进，但事实证明，在大多数实际网络部署中，指标很少变化，只是在网络管理员的控制下，而不是如上所述自动控制。其原因部分在于传统观念认为动态变化的指标过于不稳定，即使这可能不是真的。也许更重要的是，今天许多网络都缺乏ARPANET中普遍存在的链路速度和延迟的巨大差异。因此，静态指标是常态。设置度量的一种常用方法是使用常量乘以（1 / link_bandwidth）。



重点外卖



为什么我们仍然讲述一个不再使用的数十年前算法的故事？因为它完美地说明了两个宝贵的教训 首先，计算机系统通常*基于经验迭代设计。* 我们很少在第一时间做到正确，所以尽早部署一个简单的解决方案非常重要，并期望随着时间的推移改进它。无限期地陷入设计阶段通常不是一个好方法。第二个是众所周知的KISS原则：*保持简单，愚蠢。* 在构建复杂系统时，通常更少。发明复杂优化的机会很多，这是一个很有诱惑力的机会。虽然这种优化有时具有短期价值，但令人震惊的是，随着时间的推移，简单方法的证明最佳。这是因为当一个系统有许多移动部件时，正如互联网最肯定的那样，保持每个部件尽可能简单通常是最好的选择。

内容[网络作为图表](https://book.systemsapproach.org/internetworking/routing.html#network-as-a-graph)[距离矢量（RIP）](https://book.systemsapproach.org/internetworking/routing.html#distance-vector-rip)[链路状态（OSPF）](https://book.systemsapproach.org/internetworking/routing.html#link-state-ospf)[度量](https://book.systemsapproach.org/internetworking/routing.html#metrics)

# 3.4实施

到目前为止，我们已经讨论过交换机和路由器必须做什么而不描述它们是如何做到的。有一种直接的方法来构建交换机或路由器：购买通用处理器并配备多个网络接口。运行合适软件的这种设备可以在其一个接口上接收数据包，执行本章所述的任何交换或转发功能，并将数据包发送到其另一个接口。这种所谓的*软件交换机*与许多商业中低端网络设备的架构相差无几。提供高端性能的实现通常会利用额外的硬件加速。我们将这些称为*硬件开关*虽然这两种方法显然都包含硬件和软件的组合。

本节概述了以软件为中心和以硬件为中心的设计，但值得注意的是，在交换机与路由器的问题上，区别并不是一个大问题。事实证明，交换机和路由器的实现有很多共同点，网络管理员通常会购买一个转发盒，然后将其配置为L2交换机，L3路由器或两者的某种组合。由于它们的内部设计非常相似，我们将在本节中使用“ *切换* ”一词来涵盖两种变体，避免了一直说“开关或路由器”的乏味。我们会在适当时调出两者之间的差异。

## 软件开关

[图1](https://book.systemsapproach.org/internetworking/impl.html#softswitch)显示了使用带有四个网络接口卡（NIC）的通用处理器构建的软件交换机。到达NIC 1并在NIC 2上转发的典型数据包的路径很简单：当NIC 1收到数据包时，它通过I / O总线将其字节直接复制到主存储器中（本例中为PCIe） ）使用一种称为*直接内存访问*的技术 （DMA）。一旦数据包在内存中，CPU检查其标头以确定应该将数据包发送到哪个接口，并指示NIC 2再次使用DMA直接从主存储器发送数据包。重要的一点是，数据包在主存储器中缓冲（这是存储转发的“存储”的一半），CPU只将必要的标题字段读入其内部寄存器进行处理。

![img](https://book.systemsapproach.org/internetworking/figures/impl/Slide1.png)用作软件开关的通用处理器。

这种方法存在两个潜在的瓶颈，其中一个或两个限制了软件交换机的聚合分组转发容量。

第一个问题是性能受到所有数据包必须进出主存储器的事实的限制。您的里程数将根据您愿意为硬件支付的费用而有所不同，但作为示例，受1333-MHz，64位宽内存总线限制的计算机可以以略高于100 Gbps的峰值速率传输数据 - 建立一个带有少量10-Gbps以太网端口的交换机，但对于互联网核心的高端路由器来说还不够。

而且，这个上限假定移动数据是唯一的问题。对于长数据包来说这是一个公平的近似，但是当数据包很短时这是一个糟糕的数据包，这是交换机设计者必须计划的最坏情况。对于最小化的数据包，处理每个数据包的成本 - 解析其报头并决定将其传输到哪个输出链路 - 可能占主导地位，并可能成为瓶颈。例如，假设处理器可以执行所有必要的处理以每秒切换4000万个数据包。这有时称为每秒数据包（pps）速率。如果平均数据包是64字节，这意味着

吞吐量= pps x BitsPerPacket

= 40 \次10 ^ 6 \次64 \次8= 4 0 × 1 0 6 × 6 4 × 8

= 2048 \次10 ^ 7= 2 0 4 8 × 1 0 7

也就是说，吞吐量大约为20 Gbps，但大大低于用户对其交换机要求的范围。请记住，连接到交换机的所有用户都将共享此20 Gbps，就像连接到共享介质的所有用户共享单个（未切换）以太网段的带宽一样。因此，例如，具有该聚合吞吐量的16端口交换机将仅能够处理每个端口上大约1Gbps的平均数据速率。

> 这些示例性能数字并不代表在高端服务器上运行的高度调整的软件可以实现的绝对最大吞吐率，但它们表明在追求这种方法时最终面临的限制。

在评估交换机实施时，最后一个考虑因素很重要。本章讨论的非平凡算法 - 学习桥使用的生成树算法，RIP使用的距离矢量算法，以及OSPF使用的链路状态算法 - *不是*每个数据包转发决策的直接部分。它们在后台定期运行，但是交换机不必为它转发的每个数据包执行OSPF代码。CPU可能基于每个数据包执行的最昂贵的例程是表查找，例如，查找VC表中的VCI编号，L3转发表中的IP地址或L2中的以太网地址转发表。



重点外卖



这两种处理之间的区别非常重要，可以为其命名：*控制平面*对应于“控制”网络所需的后台处理（例如，运行OSPF，RIP或下一章中描述的BGP协议）和*数据平面*对应于从输入端口的数据包移动到输出口所需的每数据包的处理。由于历史原因，这种区别在蜂窝接入网络中被称为*控制平面*和*用户平面*，但是该想法是相同的，并且事实上，3GPP标准将CUPS（控制/用户平面分离）定义为架构原理。

当两个处理在同一个CPU上运行时很容易混淆，[如图1](https://book.systemsapproach.org/internetworking/impl.html#softswitch)所示的软件交换机的情况 ，但是通过优化数据平面的实现方式可以显着提高性能，相应地，指定一个井控制和数据平面之间的定义接口。

## 硬件开关

在互联网历史的大部分时间里，高性能交换机和路由器都是专用设备，采用专用集成电路（ASIC）构建。虽然使用运行C程序的商用服务器构建低端路由器和交换机是可能的，但ASIC需要达到所需的吞吐率。

ASIC的问题在于硬件设计和制造需要很长时间，这意味着向交换机添加新功能的延迟通常以数年来衡量，而不是今天软件行业习惯的几天或几周。理想情况下，我们希望受益于ASIC的性能和软件的灵活性。

幸运的是，域特定处理器（和其他商品组件）的最新进展使这成为可能。同样重要的是，利用这些新处理器的交换机的完整架构规范现在可以在线获得 - 相当于*开源软件*的硬件。这意味着任何人都可以通过从Web上拉出蓝图来构建高性能交换机（参见Open Compute Project，OCP，例如），就像构建自己的PC一样。在这两种情况下，您仍然需要在硬件上运行软件，但正如Linux可以在您自己构建的PC上运行一样，现在GitHub上可以使用开源L2和L3堆栈在家用交换机上运行。或者，您只需从商品交换机制造商处购买预置开关，然后将自己的软件加载到其上即可。下面介绍这些开放式*白盒开关*，这些*开关*被称为将它们与历史上占据行业主导地位的封闭式“黑盒”设备进行对比。

![img](https://book.systemsapproach.org/internetworking/figures/impl/Slide2.png)使用网络处理单元的白盒开关。

[图2](https://book.systemsapproach.org/internetworking/impl.html#whitebox)是白盒开关的简化描述。与早期在通用处理器上实现的主要区别在于增加了网络处理器单元（NPU），这是一个特定于域的处理器，其架构和指令集已针对处理数据包报头进行了优化（即，用于实现数据平面）。NPU在精神上类似于具有针对渲染计算机图形而优化的架构的GPU，但在这种情况下，NPU被优化用于解析分组报头并做出转发决策。NPU能够以每秒兆兆位（Tbps）的速率处理数据包（输入，做出转发决策和输出），速度足够快，可以跟上32x100-Gbps端口，或者显示的48x40-Gbps端口图。

> 我们对NPU一词的使用有点不标准。从历史上看，NPU的名称是使用更狭义的网络处理芯片，例如，用于实现智能防火墙或深度包检测。它们不像我们在这里讨论的NPU那样通用; 它们也不是高性能的。目前的方法似乎可能使专用网络处理器过时，但无论如何，我们更喜欢NPU命名符，因为它与构建可编程域特定处理器的趋势一致，包括用于图形和TPU的GPU（张量处理）人工智能的单位）。

这种新型开关设计的优点在于，现在可以将给定的白盒编程为L2开关，L3路由器或两者的组合，只需编程即可。软件开关中使用的完全相同的控制平面软件堆栈仍在控制CPU上运行，但此外，数据平面“程序”被加载到NPU上以反映由控制平面软件做出的转发决定。究竟如何“编程”NPU取决于芯片供应商，目前有几家。在某些情况下，转发管道是固定的，控制处理器只是将转发表加载到NPU中（通过固定我们的意思是NPU只知道如何处理某些报头，如以太网和IP），但在其他情况下，转发管道本身是可编程的。P4是一种新的编程语言，可用于编程这种基于NPU的转发管道。除此之外，P4试图隐藏底层NPU指令集中的许多差异。

在内部，NPU利用三种技术。首先，基于SRAM的快速存储器在处理数据包时对其进行缓冲。SRAM（静态随机存取存储器）比主存储器使用的DRAM（动态随机存取存储器）快大约一个数量级。其次，基于TCAM的存储器存储要在正被处理的分组中匹配的比特模式。TCAM中的“CAM”代表“内容可寻址内存”，这意味着您要在表中查找的密钥可以有效地用作实现该表的内存中的地址。“T”代表“三元”，这是一种奇特的方式，可以说你要查找的密钥可以在其中包含通配符（例如，密钥`10*1`匹配两者`1001`和`1011`）。最后，转发每个分组所涉及的处理由转发管道实现。该管道由ASIC实现，但是在设计良好时，可以通过更改其运行的程序来修改管道的转发行为。在高级别，此程序表示为*（匹配，操作）*对的集合：如果您在标头中匹配此类字段，则执行此操作或该操作。

由多级流水线而不是单级处理器实现的分组处理的相关性是转发单个分组可能涉及查看多个报头字段。可以对每个阶段进行编程以查看不同的字段组合。多级流水线为每个数据包增加了一点端到端延迟（以纳秒为单位），但也意味着可以同时处理多个数据包。例如，阶段2可以在数据包A上进行第二次查找，而阶段1在数据包B上进行初始查找，依此类推。这意味着NPU作为一个整体能够跟上线速度。在撰写本文时，最先进的技术是12.8 Tbps。

最后，[图2](https://book.systemsapproach.org/internetworking/impl.html#whitebox)包括其他商品组件，使这一切都很实用。特别是，现在可以购买可插拔的*收发器*模块，它可以处理所有媒体访问细节 - 无论是千兆以太网，万兆以太网还是SONET - 以及光纤。这些收发器都符合标准化的形状因子，例如SFP +，它们又可以通过标准化总线（例如，SFI）连接到其他组件。同样，关键的一点是，网络行业刚刚进入计算行业过去二十年所享有的商品化世界。

## 软件定义网络

随着交换机变得越来越商品化，注意力正在转移到控制它们的软件上。这使我们正处于构建*软件定义网络* （SDN）的趋势中，这一想法在大约十年前开始萌芽。事实上，正是SDN的早期阶段引发了网络行业向白盒交换机的转变。

SDN的基本思想是我们已经讨论过的：将网络控制平面（即路由算法，如RIP，OSPF和BGP运行）与网络数据平面（即进行数据包转发决策的地方）分离，前者转移到商用服务器上运行的软件，而后者则由白盒交换机实现。SDN背后的关键使能理念是将这种解耦更进一步，并在控制平面和数据平面之间定义标准接口。这样做允许控制平面的任何实现与数据平面的任何实现进行通信; 这打破了对任何一个供应商的捆绑解决方案的依赖。原始接口称为*OpenFlow*，这种解耦控制和数据平面的想法被称为分解。

> 前一小节中提到的P4语言是通过概括OpenFlow来定义此接口的第二代诱惑。

分解的另一个重要方面是逻辑集中控制平面可用于控制分布式网络数据平面。我们说逻辑上是集中的，因为当控制平面收集的状态保持在全局数据结构（例如网络映射）中时，该数据结构的实现仍然可以分布在多个服务器上。例如，它可以在云中运行。这对于可伸缩性和可用性都很重要，其关键是两个平面的配置和缩放彼此独立。这个想法在云中迅速发展，今天的云提供商在他们的数据中心和互连数据中心的骨干网络上运行基于SDN的解决方案。

这种设计的一个后果并不是显而易见的，逻辑上集中的控制平面不仅管理物理服务器互连的物理（硬件）交换机网络，而且还管理互连的虚拟（软件）交换机网络虚拟服务器（例如，虚拟机和容器）。如果您计算“交换机端口”（衡量连接到网络的所有设备），那么互联网上的虚拟端口数量将超过2012年的物理端口数量。

![img](https://book.systemsapproach.org/internetworking/figures/impl/Slide3.png)网络操作系统（NOS）托管一组控制应用程序并为底层网络数据平面提供逻辑上集中的控制点。

[如图3](https://book.systemsapproach.org/internetworking/impl.html#sdn)所示，SDN成功的其他关键推动因素之一 是网络操作系统（NOS）。就像服务器操作系统（例如，Linux，IOS，Android，Windows）一样，它提供了一组高级抽象，可以更容易地实现应用程序（例如，您可以读取和写入文件而不是直接访问磁盘驱动器）， NOS可以更轻松地实现网络控制功能，也称为*控制应用程序*。一个好的NOS抽象出网络交换机的细节并提供*网络地图*抽象给应用程序开发人员。NOS检测底层网络中的变化（例如，交换机，端口和上下链路），并且控制应用程序仅在该抽象图上实现它想要的行为。这意味着NOS承担了收集网络状态的负担（分布式算法的难点部分，如链路状态和距离矢量算法），应用程序可以自由地简单地实现最短路径算法并将转发规则加载到底层交换机。通过集中这一逻辑，我们的目标是提出全球优化的解决方案。云提供商发布的已采用此方法的证据证实了这一优势。

云提供商已经能够摆脱SDN的优势，它在企业和电信公司中的应用速度要慢得多。这部分是由于不同市场管理其网络的能力。世界上的谷歌，微软和亚马逊拥有利用这项技术所需的工程师和DevOps技能，而其他人仍然更喜欢预先打包和集成的解决方案，这些解决方案支持他们熟悉的管理和命令行界面。

[关于](https://book.systemsapproach.org/)[前言](https://book.systemsapproach.org/preface.html)[第1章：基础](https://book.systemsapproach.org/foundation/problem.html)[第2章：直接连接](https://book.systemsapproach.org/direct/problem.html)[第3章：网络互联](https://book.systemsapproach.org/internetworking/problem.html)[3.1交换和桥接](https://book.systemsapproach.org/internetworking/switching.html)[3.2基本网络互联](https://book.systemsapproach.org/internetworking/basic-ip.html)[3.3路由](https://book.systemsapproach.org/internetworking/routing.html)[3.4实施](https://book.systemsapproach.org/internetworking/impl.html)[3.5更广泛的视角](https://book.systemsapproach.org/internetworking/trend.html)[第4章：高级网络互联](https://book.systemsapproach.org/scaling/problem.html)[第5章：端到端协议](https://book.systemsapproach.org/e2e/problem.html)[第6章：拥塞控制](https://book.systemsapproach.org/congestion/problem.html)[第7章：端到端数据](https://book.systemsapproach.org/data/problem.html)[第8章：网络安全](https://book.systemsapproach.org/security/problem.html)[第9章：应用程序](https://book.systemsapproach.org/applications/problem.html)[与GitBook一起发布](https://www.gitbook.com/)





# [3.5更广泛的视角](https://book.systemsapproach.org/)

# 3.5更广泛的视角

## 虚拟网络一路走来

几乎只要有分组交换网络，就有关如何虚拟化它们的想法，从虚拟电路开始。但是，虚拟化网络究竟意味着什么呢？

虚拟内存是一个有用的例子。虚拟内存创建了大型私有内存池的抽象，即使底层物理内存可能被许多应用程序共享，并且明显小于虚拟内存池。这种抽象使程序员能够在存在大量内存并且没有其他人正在使用它的假象下运行，而内存管理系统负责将虚拟内存映射到物理资源以及避免用户之间的冲突等事情。 。

类似地，服务器虚拟化呈现虚拟机（VM）的抽象，其具有物理机器的所有功能。同样，单个物理服务器上可能支持许多VM，并且虚拟机上的操作系统和用户很高兴不知道VM正被映射到物理资源上。

关键是计算资源的虚拟化保留了虚拟化之前存在的抽象和接口。这很重要，因为这意味着那些抽象的用户不需要改变 - 他们看到了虚拟化资源的忠实再现。虚拟化还意味着不同的用户（有时称为*租户*）不能相互干扰。那么当我们尝试虚拟化网络时会发生什么？

如[第3.2节](https://book.systemsapproach.org/internetworking/basic-ip.html)所述，VPN 是虚拟网络的早期成功之一。他们允许运营商向企业客户展示他们拥有自己的私人网络的幻想，即使实际上他们与许多其他用户共享底层链接和交换机。但是，VPN仅虚拟化一些资源，特别是寻址和路由表。如今通常理解的网络虚拟化更进一步，虚拟化网络的每个方面。这意味着虚拟网络应该支持物理网络的所有基本抽象。从这个意义上说，它们类似于虚拟机，它支持服务器的所有资源：CPU，存储，I / O等。

为此，*虚拟LAN*（VLAN）是我们通常虚拟化L2网络的方式。支持VLAN需要对原始802.1报头规范进行相当简单的扩展，`VID`在`SrcAddr`和`Type`字段之间插入12位VLAN ID（）字段，[如图1](https://book.systemsapproach.org/internetworking/trend.html#vlan)所示 。（此VID通常称为*VLAN标记*。）实际上在标头的中间插入了32位，但前16位用于保持与原始规范的向后兼容性（它们用于`Type = 0x8100`指示此frame包括VLAN扩展）; 其他四个比特保存用于确定帧优先级的控制信息。这意味着可以映射2^ {12}1 2 = 4096虚拟网络到单个物理LAN。

![img](https://book.systemsapproach.org/internetworking/figures/impl/Slide4.png)嵌入在以太网（802.1）报头中的802.1Q VLAN标记。

事实证明，VLAN对于想要隔离不同内部组（例如，部门，实验室）的企业非常有用，使每个组都拥有自己的私有LAN。VLAN也被视为在云数据中心中虚拟化L2网络的有前途的方式，使得为每个租户提供自己的L2网络以便将其流量与所有其他租户的流量隔离开来成为可能。但是存在一个问题：4096个可能的VLAN不足以说明云可能托管的所有租户，并且使问题复杂化，在云中网络需要连接*虚拟机* 而不是这些虚拟机运行的物理机器。

为解决此问题，引入了另一种称为*虚拟可扩展LAN*（VXLAN）的标准。与原始方法（有效地将虚拟化以太网帧封装在另一个以太网帧内）不同，VXLAN在UDP数据包内封装了一个虚拟以太网帧。这意味着基于VXLAN的虚拟网络（通常称为*覆盖网络*）运行在基于IP的网络之上，而该网络又在底层以太网上运行（或者可能只在底层以太网的一个VLAN中运行）。VXLAN还使一个云租户可以拥有自己的多个VLAN，这使他们可以隔离自己的内部流量。这意味着最终可以将VLAN封装在封装在VLAN中的VXLAN覆盖中。

虚拟化的强大之处在于，当正确完成时，应该可以将一个虚拟化资源嵌套在另一个虚拟化资源中，因为毕竟虚拟资源应该像物理资源一样运行，我们知道如何虚拟化物理资源！换句话说，能够虚拟化虚拟资源是您在虚拟化原始物理资源方面做得很好的最好证明。重新诠释世界海龟的神话：虚拟网络一直在向下。

实际的VXLAN标头很简单。它包括一个24位*虚拟网络ID*（VNI），以及一些标志位。它还意味着UDP源和目标端口字段的特定设置（参见 [第5.1节](https://book.systemsapproach.org/e2e/udp.html)），目标端口4789正式保留用于VXLAN。弄清楚如何唯一地识别虚拟LAN（VLAN标签）和虚拟网络（VXLAN VID）是很容易的部分。这是因为封装是虚拟化的基础; 您需要添加的是一个标识符，告诉您此封装数据包所属的许多可能用户中的哪一个。

困难的部分是在虚拟网络中嵌入（封装）虚拟网络的想法，这是网络的递归版本。另一个挑战是了解如何自动化虚拟网络的创建，管理，迁移和删除，在这方面仍有很大的改进空间。掌握这一挑战将成为未来十年网络的核心，虽然其中一些工作无疑将在专有设置中发生，但开源网络虚拟化平台（例如，Linux基金会的*Tungsten Fabric*项目）仍处于领先地位。



 更广泛的视角



要继续阅读有关互联网[云](https://book.systemsapproach.org/scaling/trend.html)化的信息，请参阅 [云正在吃互联网](https://book.systemsapproach.org/scaling/trend.html)。

要了解有关虚拟网络成熟的更多信息，我们建议：

- [网络异端](https://networkheresy.com/2012/05/31/network-virtualization/)，2012。
- [钨丝织物](https://tungstenfabric.github.io/website/)，2018年。

