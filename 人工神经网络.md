# 第一节 人工神经网络基础

智能

智能处理

计算机学科的三个根本性问题

巴贝奇问题 自动计算

图灵问题 智能问题

布什问题 信息的广义互联

巴贝奇问题 已经有了很大的进展

布什问题 也有了成熟的方案

图灵问题，进展滞后

图灵测试

计算机器与智能

测试者与被测试者随意提问，能不能判断是不是机器

智能的机器化

图灵问题

达特茅斯会议

专家系统

语音智能

BP算法

深蓝

深度学习

alphago

智能技术的发展

图灵问题还没有终极的解决方案

图灵奖

人工智能鼻祖

智能的源头

大脑具有智能

功耗低

体积小

重量小

突触神经元

神经元 突触

借鉴人的大脑

1943年 心理学家 逻辑学家

每个神经元抽象为数字，连接也抽象为数字，形成了一个网络

外界输入 激活函数 输出

简单分类问题

yes or no

70年过去

人工智能 机器学习 深度学习

简单神经元

单层感知机

单程感知机不能解决XoR问题

反向传播算法

卷积神经网络

深度学习，多层大规模的神经网络

深度学习下围棋

感知机

模拟神经元

单层感知机

输入输出两层

激活函数 加权

前馈神经网络

多个感知机拼接，多层感知机

一层数据送到下一层

参数可调节

训练样本

反向传播 

梯度下降

调整参数

重复进行

卷积神经网络

图像的卷积就是提取三角，锐化的功能

卷积总和的输出

借鉴了生物的视皮层

卷积层的概念

- 局部连接
- 权重共享
- 空间或时间的降采样

卷积神经网络

- 逐层抽象
- 处理更加深刻的信息
- 图像视频的理解
- 环境的感知

缺乏反馈

# 第二节 人工神经网络发展现状

卷积神经网络 前馈神经网络 变长的输入

每一个语音文字含义与上下文有关

RNN 循环神经网络

- 记忆能力
- 注意力机制
- 应用
  - 机器翻译
  - 图片描述
  - 视频标注

海与语境有关的含义

DeepMind

AlphaGo

神经图灵机

神经网络来实现图灵机的读写操作

由训练来学习

通过神经网络自己学习编程

生成对抗网络GAN

- 网络一 训练出学习新样本，为无监督学习提供算法支持
- 判定学习出的新样本与老样本是否一致
- 警察照片
  - 生成网络 制造假的照片
  - 判别模型 判断你是哪的照片
- 生成与判别相互促进
- 生成器 以假乱真
- 判别器 火眼金睛
- 互相对抗 提升
- 突破性的进展
- 超分辨率，手机摄像
- 人脸去遮挡

1943 提出人工神经网络

卷积神经网络

生成对抗网络

神经网络打德州扑克



**硬件支持**

人工神经网络（深度学习）

传统芯片处理神经网络十分低效

芯片的能耗很高

最大的人工神经网络不过几百亿个突触

比人类还是要小的，差三到四个数量级

图形处理 GPU

信号处理 DSP

智能处理

深度神经网络的芯片

智能算法的处理速度提升10000倍

把阿尔法狗放到手机里面

图像本地处理

实施训练，不断学习

法国一块深度学习处理器架构

DianNao

计算机体系结构最佳论文

通用cpu 100倍的性能

多核架构DaDianNao

300倍提升

通用机器学习领域



# 第三节 人工神经网络硬件实现

深度学习处理器

DianNao

算法 神经元 突触

芯片 神经元 突触

问题：

- 深度神经网络的规模太大，芯片突触不可能做到一一对应
- 访存问题，内存带宽有限，即使神经元很多，访存限制也会限制
- 读取耗能大于就算耗能
- 时分复用，小尺寸应对大规模
- 矛盾
  - 硬件神经元有限，算法无限
  - 硬件神经元固定而算法不固定
- 时分复用
  - 每次计算一小块，蚂蚁搬大米
  - 突触与缓存，连接起来
  - 不是硬件堆一堆
  - 为什么独立的缓存
    - 数据的特性不同
    - 单核到多核的变化
- 数据大概几十G,每个芯片存一点，都在芯片上处理
- EDRAM  增强动态随机存取
  - 缺点：周期性刷新
  - 摧毁性的读
- SRAM 静态随机存储器
- 丢失刷新对于神经元是正常的
- EDRAM与神经网络很合适
- 不访问内存，性能高，能耗低

PuDianNao

多样的机器学习算法

学习方法

- 监督学习
- 半监督学习
- 无监督学习
- 主动学习
- 增强学习



多算法加速器设计策略

分析算法的计算模式的数据局部性

- 寻找最耗时的操作（计算的共性）
- 研究局部性，降低访存需求（数据的共性）

K-NN,Kmeans,贝叶斯，决策树，深度神经网络，

五种神经算子

- 向量内积
- 向量距离
- 计数
- 排序
- 非线性函数

PuDianNao

性能高，功耗小，体积小

ShiDianNao

摄像头

图像，不光拍下来，还要理解图像，摄像头数据很多，存一两个星期

小体积，小功耗里执行神经网络算法，规避访存

- 输入图像
- 神经网络模型

图像直接拍出来就处理

模型：卷积神经网络 突触可以复用

减少访存，比cpu减少耗能

神经网络进展：

指令集

arm x86

软硬件的接口，硬件设计者提供的功能

智能时代·

智能指令集

- 寒武纪
- 精简指令集
- 矩阵，向量指令
- 新指令编写神经网络算法更加精简

